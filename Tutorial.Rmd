---
title: "Growing Shade methods"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: 
  github_document:
    toc: true
always_allow_html: true
urlcolor: blue
---

# Introduction

This tutorial walks through how to grab and synthesize various data pieces which go into making Growing Shade. This document should be useful when doing data updates update, or trying to scale this workflow to other regions/areas.

The first time you run this code, it will be helpful to walk step-by-step through the various pieces. There are several places where you'll get instructions to request and save API keys, or other manual steps which can't be automated. However, after you walk thorough it initially, in future runs (if needed) or for small data/geography adjustments, you can probably be successful running everything in one go!

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, message = F, warning = F,
                      cache = TRUE,
                      cache.path = "cache/")
library(dplyr); library(tidyr); library(readr); library(stringr)
library(tigris)
library(sf)
library(tidycensus)
library(ggbeeswarm)
library(RSocrata)
library(here)


st_erase = function(x, y) st_difference(x, st_union(st_combine(y)))
`%not_in%` <- Negate(`%in%`)
```

# Set parameters

These global parameters dictate what state/county combinations will be used, as well as from what year various data pieces come from. Since the data pieces are updated on different schedules, it's unfortunately not as simple as setting a "global" rule to use data corresponding to the current year

This code is set up to use/process 2020-era census geographies at the block group level (even though some data sources are still using 2010-era geographies...but we'll deal with those later).

```{r set-parameters}
#####
# Geography variables
####
state <- c("MN")
county <- c("Anoka", "Carver", "Dakota", "Hennepin", "Ramsey", "Scott", "Washington") # either type in specific county names, or for all counties within a state assign `county <- NULL`

process_geographies <- TRUE 

#######
# Demographic variables
######
acs_year <- 2021 #The 2017-2021 ACS 5-year estimates are scheduled to be released on December 8, 2022. So this can be updated with "2021" then. 
census_year <- 2020

process_demographics <- FALSE

#######
# Tree canopy variables
#######

calibrate_trees <- FALSE # recommend FALSE in most cases; this gets into a pretty bespoke analysis

```

# Process demographic data

The demographic information is fetched using the APIs/app tokens. Follow these instructions:

You will need an API key from Census:

-   [Request an api key](https://api.census.gov/data/key_signup.html)
-   Enter in the console: `usethis::edit_r_environ()`
-   When the `.Renviron` file comes up in the editor, type: `CENSUS_KEY="KEY GOES HERE, INSIDE QUOTES"`
-   Save and close the `.Renviron` file.
-   Restart R.

You will need an app token from CDC:

-   [Request an app token](https://chronicdata.cdc.gov/profile/edit/developer_settings)
-   You may have to create an account with Tyler Data & Insights ID
-   More information about "app tokens" and metadata are on the [PLACES data overview](https://dev.socrata.com/foundry/chronicdata.cdc.gov/cwsq-ngmh)
-   Note that CDC has APIs and app tokens. It's a bit confusing, but be sure you are looking at the app token for this.
-   Enter in the console: `usethis::edit_r_environ()`
-   When the `.Renviron` file comes up in the editor, type: - `CDC_KEY="APP TOKEN GOES HERE, INSIDE QUOTES"` - `CDC_EMAIL="email you signed up with goes here, inside quotes"`
-   `CDC_PASSWORD="password you used to signup with goes here, inside quotes"`
-   Save and close the `.Renviron` file.
-   Restart R.

## Decennial census

Race variables come from the decennial 2020 census. Currently, the decennial census data is preferred over ACS data because it is a population count rather than a sample and because ACS data uses the average of 5 years (so starting with the ACS 2021-2025 data, it may be logical to switch over to using the ACS data instead).

```{r decennial}
if (process_demographics == TRUE) {
  census_api_key(Sys.getenv("CENSUS_KEY"))
  
  race_var <- c(
    "P2_005N", # white nh
    "P2_006N", # black nh
    "P2_007N", # amin nh
    "P2_008N", # asian nh
    "P2_009N", # hawaiian pi nh
    "P2_010N", # some other nh
    "P2_011N", # 2+ nh
    "P2_002N" # hispanic
  )
  
  decennial_data <- get_decennial(
    geography = "block group",
    variables = race_var, 
    summary_var = "P1_001N",
    year = census_year,
    state = state,
    county = county,
    geometry = F
  ) %>%
    pivot_wider(names_from = variable, values_from = value) %>%
    
    mutate(across(starts_with("P2"), ~ .x / summary_value)) %>%
    rename(whitenh = P2_005N,
           pblacknh = P2_006N,
           pamindnh = P2_007N,
           phisppop = P2_002N) %>%
    mutate(pothmultnh = (P2_010N + P2_011N),
           pasiannh = (P2_008N + P2_009N),
           pbipoc = 1 - whitenh) %>%
    select(-c(starts_with("P2"), summary_value, NAME))
  
  save(file = paste0(here::here(), "/data-raw/decennial_data.rda"), decennial_data)
} else {
  load(paste0(here::here(), "/data-raw/decennial_data.rda"))
}
```

## American Community Survey

Other demographic variables come from the American Community Survey 5-year data. ACS numbers come from a surveyed population sample.

Check what is the most [recent year of ACS data here](https://api.census.gov/data.html). Search for "acs5" and see what is the most recent year of data available.

```{r acs}
if (process_demographics == TRUE) {
  census_api_key(Sys.getenv("CENSUS_KEY"))
  
  v20 <- load_variables(acs_year, "acs5", cache = TRUE)
  View(v20 %>% filter(geography == "block group"))
  #  you may need to access the table shells: https://www.census.gov/programs-surveys/acs/technical-documentation/table-shells.html
  #  census reporter topics are also very useful! https://censusreporter.org/topics/
  
  acs_variables <- c(
    "B01001_001", #poptotal
    paste0("B01001_00", c(3:6)), #under18 m
    paste0("B01001_0", c(27:30)), #under18 f
    paste0("B01001_0", c(20:25, 44:49)), #over 65m, f
    "B19013_001",# median hh income
    "B25003_001", #tenure_total
    "B25003_002", #tenure owners
    "B23025_001", #employment status denominator
    "B23025_007", #unemployed
    paste0("C17002_00", c(1:6)) #poverty status
  )
  
  acs_data <-  get_acs(
    geography = "block group",
    variables = acs_variables,
    survey = "acs5",
    state = state,
    county = county,
    year = acs_year
  ) %>%
    select(-moe, -NAME) %>%
    pivot_wider(names_from = variable, values_from = estimate)  %>%
    rowwise() %>% 
    #process to useable forms of the data
    mutate(
      under18 = 
        sum(c(B01001_003, B01001_004, B01001_005,
              B01001_006, B01001_027, 
              B01001_028, B01001_029, B01001_030),
            na.rm = T),
      over65 = sum(c(B01001_020, B01001_021, B01001_022, 
                     B01001_023, B01001_024, 
                     B01001_025, B01001_044, B01001_045,
                     B01001_046, B01001_047, 
                     B01001_048, B01001_049), na.rm = T)) %>% 
    mutate(across(c(under18, over65), ~.x / B01001_001),  #, .names = "{.col}_percent"),
           sensage = under18 + over65,
           pownhome = B25003_002 / B25003_001,
           pwk_nowork = B23025_007 / B23025_001,
           ppov185 = (C17002_002 + C17002_003 + C17002_004 + C17002_005 + C17002_006) / C17002_001) %>%
    rename(hhincome = B19013_001) %>%
    select(c(GEOID, !starts_with(c("B", "C"))))
  
  save(file = paste0(here::here(), "/data-raw/acs_data.rda"), acs_data)
} else {
  load(paste0(here::here(), "/data-raw/acs_data.rda"))
}

```

## PLACES health data

Health metrics come from [PLACES: Local Data for Better Health, Census Tract Data](https://chronicdata.cdc.gov/500-Cities-Places/PLACES-Local-Data-for-Better-Health-Census-Tract-D/cwsq-ngmh). I am not aware that there is a way to use a "health_year" parameter to get a specific timestamp of the data, so please just double check that the most recent data is being used! CDC has indicated that they *might* soon be switching over to using 2020-vintage census geographies rather than the old 2010 geographies, so the processing will get simplified at that point.

Also, because this CDC data currently uses old census geographies, you will need to download a crosswalk - Download the state-specific crosswalk of ["Block Groups --\> Census Tracts" for year "2010 --\> 2020" from NHGIS](https://www.nhgis.org/geographic-crosswalks#download-from-block-groups) - Place the resultant file in the data-raw folder

```{r health}
##########
# CDC health data
#########
# variable options are documented here: https://www.cdc.gov/places/measure-definitions/index.html

if (process_demographics == TRUE) {
  
  raw_health <- read.socrata(
    # "https://chronicdata.cdc.gov/resource/cwsq-ngmh.json?$where=stateabbr in('MN', 'WI')",
    paste0("https://chronicdata.cdc.gov/resource/cwsq-ngmh.json?$where=stateabbr in('", state, "')"),
    app_token = Sys.getenv("CDC_KEY"), 
    email     = Sys.getenv("CDC_EMAIL"), 
    password  = Sys.getenv("CDC_PASSWORD")) %>%
    
    #get the columns of interest. there are more variables as an fyi though!
    # names(bg_health)
    # levels(as.factor(bg_health$measure))
    filter(measure %in% c("Current asthma among adults aged >=18 years",
                          "Chronic obstructive pulmonary disease among adults aged >=18 years",
                          "Mental health not good for >=14 days among adults aged >=18 years",
                          "Physical health not good for >=14 days among adults aged >=18 years")) %>%
    dplyr::select(locationname, measureid, data_value) %>%
    mutate(data_value = as.numeric(data_value) / 100) %>% #change to fraction
    pivot_wider(names_from = measureid, values_from = data_value)
  
  fips <- tigris::lookup_code(state = state) %>%
    stringr::str_split("'", simplify = T)
  
  crosswalk <- read_csv(paste0(here::here(), "/data-raw/nhgis_bg2020_tr2010_", fips[,2], ".csv"),
                        col_types = c('tr2010ge' = 'c',
                                      "bg2020ge" = "c")) %>%
    select(tr2010ge,#census geoid for 2010
           bg2020ge,#census geoid for 2020
           wt_pop) %>% #use weighted population crosswalk
    group_by(bg2020ge) %>%
    slice(which.max(wt_pop)) %>% # just get the crosswalk for where most people live. it's oversimplified, but pretty decent esp since block groups generally nest nicely into tracts across census geographies
    select(-wt_pop)
  
  
  ## translate health data into 2020 geographies
  health_data <- raw_health %>%
    full_join(crosswalk, by = c("locationname" = "tr2010ge"))
  
  save(file = paste0(here::here(), "/data-raw/health_data.rda"), health_data)
} else {
  load(paste0(here::here(), "/data-raw/health_data.rda"))
}

```

# Process geographies

Growing Shade is set up to have data at the block group, neighborhood, and city/township (ctu) levels.

### Census block groups

Getting these geography files is easy - just downloaded directly.

```{r census-geography}
bg_geo <- block_groups(state = state, 
                       county = county,
                       year = census_year) 

# sf::st_write(bg_geo, "/Users/escheh/Documents/GitHub/planting.shade/storymap-info/shapefiles/bg_geo.shp", append = FALSE)

```

### Neighborhoods and city levels

Since we're going to be making a map which shows census tracts, cities, or neighborhoods depending on the user input, a crosswalk needs to be made which relates block groups to the city and neighborhood levels.

If you can't download with a code-based method, download specific geographies, and put them in the data-raw folder. For the Twin Cities, neighborhoods need to be downloaded manually.

-   [Minneapolis](https://opendata.minneapolismn.gov/datasets/communities/explore?location=44.970861%2C-93.261718%2C12.85)
-   [St. Paul](https://information.stpaul.gov/City-Administration/District-Council-Shapefile-Map/dq4n-yj8b)
-   [Brooklyn Park](https://gis.brooklynpark.org/neighborhoodinfo/) (but we aren't including their neighborhoods yet)

Adjust the code below as necessary to ensure that both `nhood_geo` (neighborhoods) and `ctu_geo` (city/townships) have a column named `GEO_NAME` and `geometry`. For the neighborhood data, there should also be a `city` column (i.e., "Minneapolis" or "St. Paul" for the Twin Cities region).

After the raw geographies are downloaded, then you need to make a crosswalk which relates block groups into neighborhoods and cities. For this step, it is useful to remove major river features (boundaries around rivers often are poorly aligned, removing rivers makes generating the crosswalk much cleaner). At least in the Twin Cities, several block groups legitimately do fall within multiple cities, so this step is a admittedly a bit complicated. A simpler alternative is to just use the city/township in which the majority of the block group falls.

If this section doesn't apply for other regions, it should be easy enough to remove elements in the user-interface of the application.

```{r nhood-ctu-geo}

# neighborhood
minneap <- read_sf(paste0(here::here(), "/data-raw/minneapolis communities/Minneapolis_Communities.shp")) %>%
  rename(GEO_NAME = CommName) %>%
  mutate(Shape_Area = as.numeric(st_area(.))) %>%
  mutate(city = "Minneapolis")

stpaul <- read_sf(paste0(here::here(), "/data-raw/stpaul communities/geo_export_0c076f52-d6ff-4546-b9fa-bd9980de6e8a.shp")) %>%
  mutate(Shape_Area = as.numeric(st_area(.))) %>%
  rename(GEO_NAME = name2) %>%
  mutate(city = "St. Paul") %>%
  mutate(GEO_NAME = case_when(GEO_NAME == "CapitolRiver Council" ~ "Downtown",
                              GEO_NAME == "Thomas-Dale/Frogtown" ~ "Frogtown",
                              GEO_NAME == "West Side Community Organization" ~ "West Side",
                              GEO_NAME == "West 7th Federation/Fort Road" ~ "West 7th-Fort Road",
                              GEO_NAME == "Highland" ~ "Highland Park",
                              GEO_NAME == "Summit Hill Association" ~ "Summit Hill",
                              GEO_NAME == "Eastview-Conway-Battle Creek-Highwood Hills" ~ "Battle Creek-Conway-Eastview-Highwood Hills",
                              GEO_NAME == "The Greater East Side" ~ "Greater East Side",
                              GEO_NAME == "Como" ~ "Como Park",
                              TRUE ~ GEO_NAME))

nhood_geo <- bind_rows(minneap, stpaul) 

#### ctus -----------
temp <- tempfile()
temp2 <- tempfile()
download.file(
  "https://resources.gisdata.mn.gov/pub/gdrs/data/pub/us_mn_state_metc/bdry_metro_counties_and_ctus/shp_bdry_metro_counties_and_ctus.zip",
  destfile = temp
)
unzip(zipfile = temp, exdir = temp2)
list.files(temp2)

ctu_geo <- sf::read_sf(paste0(temp2, pattern = "/CTUs.shp")) %>%
  transmute(GEO_NAME = CTU_NAME,
            Shape_Area = Shape_Area) 

files <- list.files(temp2, full.names = T)
file.remove(files)

```

```{r ctu-nhood-crosswalk}
temp <- tempfile()
download.file("ftp://ftp.gisdata.mn.gov/pub/gdrs/data/pub/us_mn_state_metc/water_lakes_rivers/gpkg_water_lakes_rivers.zip", destfile = temp)

river_lake_all <- sf::read_sf(unzip(temp, "water_lakes_rivers.gpkg")) 

# river layer to erase major boundary rivers-------
river_lake_buffer <- river_lake_all %>%
  filter(NAME_DNR %in% c("Mississippi", "Minnesota", "St. Croix")) #%>% #these rivers are boundaries


# fxns to make easy -----
# find crosswalks
find_crosswalks <- function(x) {
  crosswalk <- x %>%
    st_transform(26915) %>%
    st_buffer(-150) %>% #buffer the perimeter of the geography
    st_erase(river_lake_buffer %>%
               st_buffer(200) %>% #buffer out rivers
               st_union() %>% 
               st_buffer(0)) %>% 
    st_intersection(bg_geo %>% 
                      dplyr::select(GEOID) %>%
                      rename(tract_id = GEOID) %>%
                      st_transform(26915)) %>%
    st_drop_geometry()
  
  return(crosswalk)
}

ctu_crosswalk <- find_crosswalks(ctu_geo) %>%
  mutate(flag = case_when(GEO_NAME == "Blakeley Twp." & tract_id != "271390813001" ~ "remove", #minnesota river is squirrely
                          TRUE ~ "keep")) %>%
  filter(flag != "remove") %>% 
  dplyr::select(-flag)
nhood_crosswalk <- find_crosswalks(nhood_geo)

wide_ctu_crosswalk_1 <- ctu_crosswalk %>%
  group_by(tract_id) %>%
  count() %>%
  left_join(ctu_crosswalk) %>%
  add_column(cities = 999) %>%
  dplyr::select(tract_id, GEO_NAME, cities, n) %>%
  # spread(cities, GEO_NAME)
  pivot_wider(names_from = cities, values_from = GEO_NAME, values_fn = list) %>%
  unnest_wider(`999`) 

wide_ctu_crosswalk <- wide_ctu_crosswalk_1 %>%
  mutate(jurisdiction = paste(`...1`, `...2`, `...3`, `...4`,# `...5`, 
                              # `...6`, `...7`,
                              sep = ", ")) %>%
  dplyr::select(tract_id, jurisdiction) %>%
  mutate(jurisdiction = str_replace(jurisdiction, ", NA", ""),
         jurisdiction = str_replace(jurisdiction, ", NA", ""),
         jurisdiction = str_replace(jurisdiction, ", NA", ""),
         jurisdiction = str_replace(jurisdiction, ", NA", ""),
         jurisdiction = str_replace(jurisdiction, ", NA", ""),
         jurisdiction = str_replace(jurisdiction, ", NA", ""),
         jurisdiction = str_replace(jurisdiction, ", NA", "")) %>%
  rename(GEOID = tract_id)

usethis::use_data(ctu_crosswalk, overwrite = TRUE)
usethis::use_data(nhood_crosswalk, overwrite = TRUE)
usethis::use_data(wide_ctu_crosswalk, overwrite = TRUE)

```

# Geographic overlay files

This is probably not relevant for other regions, but here is the code.

## Redlining shapefile

HOLC Redlining; this data was originally in equity considerations dataset, but that data uses old 2010 geographies, so need to actually get the data.

Remove open water. "all non residential"

```{r holc}
## holc  ---------------
# ftp://ftp.gisdata.mn.gov/pub/gdrs/data/pub/us_mn_state_metc/plan_historic_holc_appraisal/gpkg_plan_historic_holc_appraisal.zip
temp <- tempfile()
download.file("ftp://ftp.gisdata.mn.gov/pub/gdrs/data/pub/us_mn_state_metc/plan_historic_holc_appraisal/gpkg_plan_historic_holc_appraisal.zip",
              destfile = temp
)

redline_raw <- sf::read_sf(unzip(temp, "plan_historic_holc_appraisal.gpkg")) %>%
  filter(HSG_SCALE == "Hazardous") %>% 
  sf::st_union() %>%
  sf::st_transform(4326)

fs::file_delete("plan_historic_holc_appraisal.gpkg")
```

# Remote sensing data

These items come out of Google Earth Engine analyses. Some files need to be created/exported (and then imported into GEE), and all GEE exports need to be pulled in to this code.



## Calibrate tree canopy coverage

Growing Shade prioritizes temporal accuracy for tree canopy data. While some trade-offs come with prioritizing temporal accuracy over spatial accuracy, it is essential for this project to capture on-the-ground, real-time dynamics of how Emerald Ash Borer, development patterns, and recent tree planting programs among others are changing the tree canopy.

Sentinel-2 is currently the most spatially accurate and publicly accessible remote sensing platform. However, the 10 meter squared spatial resolution of Sentinel is larger than a lot of individual tree canopies. In exploring the data, it appears as if the canopy coverage from Sentinel is little higher than what it should be (based on aerial imagery). I've chosen to calibrate the Sentinel data with the (outdated) UMN 1 meter squared land use file.

I created a grid (n = 1015) across the region, and created a model to compare the amount of trees detected with the Sentinel 2 and with the UMN 1 meter data set (for the later, the tree area is the summation of all areas which identified as coniferous trees, deciduous trees, and forested wetland).

The final calibration coefficient (at least for 2021 tree canopy) is 0.885246, meaning that Sentinel sees about 11% more trees in areas. Another way to think about this is that Sentinel detects area with at least 89% tree canopy coverage (i.e., if Sentinel sees 1,000 acres of trees, UMN sees more like 885 acres).

In other temperate, upper Midwest areas, the .88 coefficient is probably sufficient. Otherwise, figuring out and adjusting a calibration coefficient for another area likely requires some pretty bespoke analyses and has specific data set needs which may not be widely available. 


```{r, calibrate-tree-cover}

if (calibrate_trees == TRUE){
  # ######
  # # Create a gridded area across the region to calibrate sentinel tree cover with 1m2 land cover tree data
  # # In most instances, there is no need to run this gridding step more than once
  # #####
  # wholearea <- metc_region %>%
  #   summarise(st_union(.))
  # 
  # # make a equal area grid; there are 704 tracts, so I want to make at least 1000 grids I think?
  # g = st_make_grid(wholearea,
  #                  n = c(36, 36)) %>% 
  #   st_intersection(wholearea) 
  # 
  # geometry = st_sfc(lapply(1:length(g), function(x) st_geometrycollection()))
  # df <- st_sf(id = 1:length(g), geometry = g)
  # 
  # # ggplot() +
  # #   geom_sf(data = wholearea) +
  # #   geom_sf(data = df,
  # #           fill = "transparent")
  # 
  # sf::st_write(df, "~/Documents/GitHub/planting.shade/storymap-info/shapefiles/metc_grid.shp", append = FALSE)
  
  calibrate_trees <- read_csv(paste0(here::here(), "/data-raw/TreeAcresCART/UMNTreeAcres_metcgrid_scale1_year2021.csv")) %>% 
    rename(umn = `1`) %>%
    full_join(read_csv(paste0(here::here(),"/data-raw/TreeAcresCART/TreeAcres_metcgrid_year2021.csv")) %>%
                rename(sentinel = `1`),
              by = 'id')
  
  calibrate_lm <- (lm(umn ~ sentinel, data = calibrate_trees))
  calibrate_lm2 <- (lm(umn ~ 0 + sentinel, data = calibrate_trees))
  calibrate_lm3 <- (lm(umn ~ I(sentinel ^ 2), data = calibrate_trees))
  calibrate_lm4 <- (lm(log(umn) ~ sentinel, data = calibrate_trees))
  anova(calibrate_lm, calibrate_lm2, calibrate_lm3, calibrate_lm4) # the middle model is best!
  
  # AIC(calibrate_lm); AIC(calibrate_lm2); AIC(calibrate_lm3); AIC(calibrate_lm4)
  
  summary(calibrate_lm2)$r.squared # r2
  summary(calibrate_lm2)$coefficients[,4] # p-value
  
  calib_coeff <- summary(calibrate_lm2)$coefficients[,1] # coefficient
  
  save(file = paste0(here::here(), "/data-raw/calib_coeff.rda"), calib_coeff)
} else {
  load(paste0(here::here(), "/data-raw/calib_coeff.rda"))
}

calibrate_trees %>%
  ggplot(aes(x = (umn), y = (sentinel * calib_coeff))) +
  geom_point(alpha = .5) +
  geom_abline(slope=1, intercept=0, col = 'blue', lwd = 1) +
  theme_minimal()  +
  labs( x = "UMN tree acres", y = "Calibrated Sentinel tree acres")
```

## Process tree canopy cover at various geographies

```{r}

bg_canopy <- read_csv(paste0(here::here(), "/data-raw/TreeMilesIncAg_mnwi_blockgroups_year2021.csv"),
                      col_select = c(GEO_NAME, sq_miles, ALAND), col_types = c("GEO_NAME" = "c")) %>%
  mutate(sq_miles = stringr::str_remove_all(sq_miles, c("\\{groups=\\[|\\}\\]\\}")))  %>%
  
  separate(sq_miles, sep = "\\},", into = c("treeless", "trees")) %>%
  mutate(treeless = stringr::str_remove_all(treeless, "\\{classification=0, sum=|\\]\\}"),
         trees = stringr::str_remove_all(trees, "\\{classification=1, sum=|\\}\\]\\}"),
         treeless = if_else(ALAND == 0, 0, as.numeric(treeless)),
         trees = if_else(ALAND == 0, 0, as.numeric(trees)),
         percent_canopy = trees / (trees + treeless) * calib_coeff)

# canopy_ctu <- 

# canopy_nhood <- 
```

-   process GEE code to link canopy with geography
-   GEE data is in repo "users/ehe/MetCoucil/GrowingShade_CanopyCoverage"
-   <https://code.earthengine.google.com/a0da66053ecb26b668df4297c4ebed59>
-   bind everything together for city and nhood

```{r tree-canopy-summaries}
tree_summary <- function(.geo_file,
                         .crosswalk_file,
                         .canopy_file) {
  
  .geo_file %>%
    full_join(
      .crosswalk_file %>%
        left_join(bg_canopy %>%
                    rename(tract_id = bg20),
                  by = "tract_id") %>%
        group_by(GEO_NAME) %>%
        summarise(min = round(min(canopy_percent)*100, 1),
                  max = round(max(canopy_percent)*100, 1),
                  ntracts = n())) %>%
    
    full_join(.canopy_file) #%>%
  # arrange(!!!.group_factor, GEO_NAME)# %>%
  # # st_transform(4326) %>%
  # group_by(!!.group_factor) %>%
  # mutate(avgcanopy = (sum(treeacres) / sum(landacres) * calib_coeff))
}

nhood_list_raw <- tree_summary(.geo_file = nhood_geo,
                               .crosswalk_file = nhood_crosswalk,
                               .canopy_file = canopy_nhood) %>%
  arrange(city, GEO_NAME) %>%
  # st_transform(4326) %>%
  group_by(city) %>%  
  mutate(avgcanopy = (sum(treeacres) / sum(landacres) * calib_coeff))

ctu_list_raw <- tree_summary(.geo_file = ctu_geo,
                             .crosswalk_file = ctu_crosswalk,
                             .canopy_file = canopy_ctu) %>%
  arrange(GEO_NAME) %>%
  mutate(avgcanopy = (sum(treeacres) / sum(landacres) * calib_coeff))

# sf::st_write(ctu_list, "~/Documents/GitHub/planting.shade/storymap-info/shapefiles/ctu_list.shp", append = FALSE)
```

## Greenness (NDVI) Data

We do this for all land (no water!) and non-cultivated land (excluding crops/ag land).

```{r ndvi_bgs}
ndvi_uncultivated <- 
  read_csv("./TreeAcresCART/uncultivatedNDVI_blockgroups2020_year2021.csv",
           na = "No data",
           col_types = cols(GEOID = "c", `system:index` = "c", Year = 'd',  `.geo` = 'c')) %>%
  rename(GEOID = GEOID)

ndvi_allland <- 
  read_csv("../data-raw/TreeAcresCART/landNDVI_blockgroups2020_year2021.csv",
           na = "No data",
           col_types = cols(GEOID = "c", `system:index` = "c", Year = 'd',  `.geo` = 'c')) %>%
  rename(GEOID = GEOID)

# read_csv("../data-raw/TreeAcres/meanNDVI_mnwi_blockgroups_year2021.csv",
#                   na = "No data",
#                      col_types = cols(GEOID = "c", `system:index` = "c", Year = 'd', ndvi = 'd', `.geo` = 'c')) %>%
# dplyr::select(-`system:index`, -.geo, -Year)
bg_ndvi <- ndvi_uncultivated %>%
  dplyr::select(GEOID, ndvi_uncultivated) %>%
  full_join(ndvi_allland %>%
              dplyr::select(GEOID, ndvi_land)) %>%
  rename(bg20 = GEOID)
```

# Demographic variables

## Equity considerations data

There are several variables which Matt processed in advance of an equity considerations release for me with new geographies:

```{r matt-data}
matt_data <- 
  readxl::read_xlsx("./EJSCREEN_OLD_BG20.xlsx") %>%
  transmute(bg20 = BG20,
            env_cancer = ENV_CANCER) %>%
  
  full_join(
    readxl::read_xlsx("./HOLC_BG20.xlsx") %>%
      transmute(bg20 = BG20,
                holc_pred = HOLC_4_RED)) %>%
  
  full_join(
    readxl::read_xlsx("./CLIMATE_BG20.xlsx") %>%
      transmute(bg20 = BG20,
                avg_temp = AVG_TEMP,
                prim_flood = PRIM_FLOOD,
                green_roof = GREEN_ROOF
      ))

# some issues with blocks not having flood information?
readxl::read_xlsx("./CLIMATE_BG20.xlsx") %>%
  transmute(bg20 = BG20,
            avg_temp = AVG_TEMP,
            prim_flood = PRIM_FLOOD,
            green_roof = GREEN_ROOF
  ) %>%
  filter(bg20 == "270530117035")

```

# Combine all variables

Merge demographic and environmental data

```{r combinedata}
bg_growingshade_data_allMN <- 
  
  #demographics
  census_race %>%
  full_join(bg_acs) %>%
  full_join(tract_acs) %>%
  # filter(bg20 == "270531016003") %>%
  
  full_join(matt_data) %>% #equity_considerations
  full_join(bg_health3) %>%
  
  #environmental
  full_join(bg_canopy) %>%
  full_join(bg_ndvi) %>%
  
  #update some variables
  # filter(str_detect(bg10, "27003|27019|27037|27053|27123|27139|27163")) %>%
  mutate(tr20 = substr(bg20, 1, 11)) %>% #this is the tract id
  
  
  mutate(inverse_ndvi_uncultivated = ndvi_uncultivated,
         inverse_ndvi_land = ndvi_land,
         canopy_percent2 = canopy_percent,
         pop_density = poptot_mc / landacres,
         housing_density = hutot_mc / landacres) %>%
  rename(bg_string = bg20) %>%
  rowwise() %>%
  mutate(holc_pred = if_else(is.na(holc_pred), 0, holc_pred)) %>%
  
  # deal with some non residential blocks and insufficent data
  mutate(across(c(poptotal:pwk_nowork, pd_any, env_cancer:holc_pred, CASTHMA:PHLTH, pop_density:housing_density), ~ if_else(poptotal == 0, NA_real_, .x)),
         p_0017 = if_else(is.nan(p_0017), tr_p_0017, p_0017),
         p_65up = if_else(is.nan(p_65up), tr_p_65up, p_65up),
         sens_age = if_else(is.nan(sens_age), tr_sens_age, sens_age),
         mdhhincnow = if_else(is.na(mdhhincnow), tr_medianhhinc, mdhhincnow),
         phhi_qntl1 = if_else(is.na(phhi_qntl1), tr_phhi_qntl1, phhi_qntl1),
         pwk_nowork = if_else(is.na(pwk_nowork), tr_pwk_nowork, pwk_nowork)) %>%
  # mutate(across(c(poptotal:pwk_nowork, pd_any:holc_pred, CASTHMA:PHLTH, pop_density:housing_density), ~ if_else(poptotal < 10, NA_real_, .x)),
  #        across(c(poptotal:pwk_nowork, pd_any:holc_pred, CASTHMA:PHLTH, pop_density:housing_density), ~ if_else(is.na(mdhhincnow), NA_real_, .x))
  #        ) %>%
  # mutate(across(c(pblacknh:pbipoc, phhi_qntl1, pwk_nowork, env_cancer, mdhhincnow), ~ if_else((is.nan(.x) | is.na(.x)) & poptotal == 0, NA_real_, .x))) %>%
  dplyr::select(-c(pblacknh_acs:pbipoc_acs)) %>% 
  # get rid of blocks where acs has no data
  mutate(across(c(poptotal:pwk_nowork, pd_any, env_cancer:holc_pred, CASTHMA:PHLTH, pop_density:housing_density), ~ if_else(is.nan(sens_age) | is.na(sens_age), NA_real_, .x))) 
# filter(!is.na(sens_age), !is.nan(sens_age)) #get rid of block groups where there is no acs data


#%>% #and for this project, I need to rename the tract variable
# add_column(avg_temp = sample(100, size = nrow(bg_canopy), replace = TRUE),
# env_cancer = sample(100, size = nrow(bg_canopy), replace = TRUE),
# green_roof = sample(100, size = nrow(bg_canopy), replace = TRUE),
# holc_pred = sample(100, size = nrow(bg_canopy), replace = TRUE),
# luse_green = sample(100, size = nrow(bg_canopy), replace = TRUE),
# phhi_qntl1 = sample(100, size = nrow(bg_canopy), replace = TRUE),
# prim_flood = sample(100, size = nrow(bg_canopy), replace = TRUE),
# pwk_nowork = sample(100, size = nrow(bg_canopy), replace = TRUE),
# tr_ej = sample(100, size = nrow(bg_canopy), replace = TRUE)) %>%

bg_growingshade_data <- bg_growingshade_data_allMN %>%
  filter(str_detect(bg_string, "27003|27019|27037|27053|27123|27139|27163")) #just do metc region for now

filter(bg_growingshade_data_allMN, bg_string %in% c("270539800001")) #this has population, but no age component
filter(bg_growingshade_data_allMN, poptotal <10 )
filter(bg_growingshade_data_allMN, is.na(tr_medianhhinc))
# temp <- tempfile()
# download.file("https://resources.gisdata.mn.gov/pub/gdrs/data/pub/us_mn_state_metc/society_census_acs/xlsx_society_census_acs.zip",
#   destfile = temp
# )

# # tract variables of interest; some variables only exist at tract level
# acs_bgtest <- readxl::read_xlsx(unzip(temp, "CensusACSBlockGroup.xlsx")) %>%
#   janitor::clean_names()  %>%
#   filter(geog_unit %in% c("270531263002", "270531007004"))#, "270017701001"))
#   # transmute(bg20 = geog_unit,
#   #           pd_any = anydis / cdenom,
#   #           povdenom = povdenom)
# acs_bgtest$ageunder18
# acs_bgtest$age65up
# 
# acs_bgtest %>% filter(geog_unit %in% c("270531007004")) %>% dplyr::select(geog_unit, poptotal, meanhhinc, medianhhi)#, "270531007004"))
# 
# census_race %>% filter(bg20 %in% c("270531263002"))# %>% dplyr::select(geog_unit, meanhhinc, medianhhi, poptotal)#, "270531007004"))
# acs_bgtest %>% filter(geog_unit %in% c("270531263002")) %>% dplyr::select(geog_unit, poptotal, meanhhinc, medianhhi)#, "270531007004"))
# 
# fs::file_delete("CensusACSTract.xlsx")
```

Add some metadata.

```{r make-metadata}
gs_data_codes <- tribble(~variable, ~name, ~type, ~interpret_high_value, ~cc, ~ej, ~ph, ~cons,
                         "pop_density", "Population density (persons / acre)", "people",  "high_opportunity", 0, 0, 0,  0,
                         "housing_density", "Housing unit density (units / acre)", "people",  "high_opportunity", 0, 0, 0,  0,
                         "ppov185",	"% people with income <185% of the poverty threshold", "dollar", "high_opportunity", 0, 1, 0, 0,
                         "prim_flood", "% developed acres in primary flood zone", "environment", "high_opportunity", 1, 0, 0, 0,
                         "pbipoc", "Race, % people of color", "people", "high_opportunity", 0, 1, 0, 0,
                         "p_0017", "Age, % under age 18", "people",  "high_opportunity", 0, 0, 0, 0, 
                         "p_65up", "Age, % age 65 or older", "people",  "high_opportunity", 0, 0, 0,  0,
                         "avg_temp", "Temperature on hot summer day", "environment",  "high_opportunity", 1, 0, 1, 0,
                         "env_cancer", "Lifetime cancer risk from air toxics", "health", "high_opportunity", 0, 0, 1,  0,
                         
                         "ndvi_uncultivated", "Greenness, uncultivated land (2021 NDVI)", "environment", "low_opportunity", 1, 0, 1,  0,
                         "inverse_ndvi_uncultivated", "Greenness, uncultivated land (2021 NDVI) - for conservation", "environment", "high_opportunity", 0, 0, 0, 1,
                         
                         "ndvi_land", "Greenness, all land (2021 NDVI)", "environment", "low_opportunity", 1, 0, 1,  0,
                         "inverse_ndvi_land", "Greenness, all land (2021 NDVI) - for conservation", "environment", "high_opportunity", 0, 0, 0, 0,
                         
                         "tr_ej", "MPCA area of environmental justice concern", "environment", "high_opportunity", 0, 0, 0, 0,
                         "holc_pred", "% of block group's land acreage redlined", "environment", "high_opportunity", 0, 0, 0, 0,
                         "canopy_percent", "Tree canopy in 2021 (%)", "environment", "low_opportunity", 1, 0, 1, 0,
                         "canopy_percent2", "Tree canopy in 2021 (%) - for conservation", "environment", "high_opportunity", 0, 0, 0, 1,
                         "mdhhincnow", "Median household income", "dollar", "low_opportunity", 0, 0, 0, 0, 
                         "sens_age", "Age, % under age 18 or 65+", "people", "high_opportunity", 0,0,1,0,
                         "pd_any", "Disability, % any disability", "people", "high_opportunity", 0, 0, 0, 0,
                         "pblacknh", "Race, % Black or African American", "people", "high_opportunity", 0, 0, 0, 0,
                         "pothmultnh", "Race, % Multiracial or other", "people", "high_opportunity", 0, 0, 0, 0,
                         "pasiannh", "Race, % Asian or Pacific Islander", "people", "high_opportunity", 0, 0, 0, 0,
                         "phisppop", "Race, % Hispanic or Latino", "people", "high_opportunity", 0, 0, 0, 0,
                         "pamindnh", "Race, % Indigenous", "people", "high_opportunity", 0, 0, 0, 0,
                         "pwk_nowork", "% of unemployed residents", "dollar", "high_opportunity", 0, 0, 0, 0, # age 16-64 who did not work in past 12 months
                         "pownhome", "% of residents who own their home", "dollar", "high_opportunity", 0,0,0,0,
                         "MHLTH", "Mental health not good for >=14 days among adults (%)", "health", "high_opportunity", 0,0,0,0,
                         "PHLTH", "Physical health not good for >=14 days among adults (%)", "health", "high_opportunity", 0,0,0,0,
                         "COPD", "Chronic obstructive pulmonary disease among adults (%)", "health", "high_opportunity", 0,0,0,0,
                         "CASTHMA", "Asthma among adults (%)", "health", "high_opportunity", 0,0,0,0
)
```

Standardize and re-scale variables so we can create equally weighted priority scores. Do *not* include spatial data at this point, it should be joined after summarizing to save computational time.

```{r standardize-rescale}

bg_growingshade_main <- bg_growingshade_data %>%
  pivot_longer(names_to = "variable", values_to = "raw_value", -c(bg_string, tr20)) %>% #end the code after this line if you just want the reshaped data
  group_by(variable) %>%
  mutate(MEAN = mean(raw_value, na.rm = T),
         SD = sd(raw_value, na.rm = T),
         MIN = min(raw_value, na.rm = T),
         MAX = max(raw_value, na.rm = T),
         COUNT = as.numeric(sum(!is.na(raw_value))),
         z_score = (raw_value - MEAN)/SD) %>%
  
  full_join(gs_data_codes, by = 'variable') %>%
  
  #create nominal weights
  mutate(weights_nominal = case_when(interpret_high_value == "high_opportunity" ~ (raw_value - MIN) / (MAX - MIN) * 10,
                                     interpret_high_value == "low_opportunity" ~ 10 - (raw_value - MIN) / (MAX - MIN) * 10,
                                     TRUE ~ NA_real_)) %>%
  
  #Weights Standard Score
  mutate(weights_scaled = case_when(interpret_high_value == "high_opportunity" ~ pnorm(z_score) * 10,
                                    interpret_high_value == "low_opportunity" ~ (10 - pnorm(z_score) * 10),
                                    TRUE ~ NA_real_)) %>%
  
  #weights rank
  mutate(weights_rank = case_when(interpret_high_value == "high_opportunity" ~ min_rank(desc(weights_nominal)) / COUNT * 10,
                                  interpret_high_value == "low_opportunity" ~ min_rank(desc(weights_nominal)) / COUNT * 10,
                                  TRUE ~ NA_real_)) %>%
  
  # #rank
  mutate(overall_rank = case_when(interpret_high_value == "high_opportunity" ~ min_rank(desc(as.numeric(weights_nominal))),
                                  interpret_high_value == "low_opportunity" ~ min_rank(desc(as.numeric(weights_nominal))))) %>%
  #clean
  dplyr::select(-MEAN, -SD, -MIN, -MAX)  %>%
  full_join(wide_ctu_crosswalk %>% rename(tr20 = GEOID)) %>%
  filter(!is.na(name))

########
# save data
########
usethis::use_data(bg_growingshade_main, overwrite = TRUE)
gs_data_codes %>% arrange(type, name)%>% dplyr::select(type, name)

```

# Create independant files for export

## Regional averages

Create some regional averages. While the average values for the block groups are needed to create zscores, those averages are not the regional averages. Ex average median income of block groups might be 60,000 but the regional average might be lower if there are more people living in ares with lower income.

```{r regional-averages}
# ########
# # create metadata
# #########
md1 <- bg_growingshade_main %>% 
  group_by(variable) %>% 
  summarise(MEANRAW = mean(raw_value, na.rm = T),
            MEANSCALED = mean(weights_scaled, na.rm = T))

temp <- tempfile()
download.file("https://resources.gisdata.mn.gov/pub/gdrs/data/pub/us_mn_state_metc/society_census_acs/xlsx_society_census_acs.zip",
              destfile = temp
)
acs_tr2 <- readxl::read_xlsx(unzip(temp, "CensusACSTract.xlsx")) %>%
  janitor::clean_names()

acs_metadata <-
  acs_tr2 %>% #use tracts becuase it has info about disability
  filter(str_detect(geoid, "27003|27019|27037|27053|27123|27139|27163"),
         year == 2020) %>% #just do metc region for now
  dplyr::select(geoid, poptotal:pphother) %>%
  pivot_longer(names_to = "variable", values_to = "values", -geoid) %>%
  group_by(variable) %>%
  summarise(SUM = sum(values, na.rm = T)) %>%
  pivot_wider(names_from = variable, values_from = SUM) %>%
  transmute(rgn = "twin cities",
            ppov185 = (povertyn + poverty150 + pov150_185) / povdenom,
            pbipoc = (poptotal - whitenh) / poptotal,
            pamindnh = (amindnh) / poptotal,
            phisppop = hisppop / poptotal,
            pblacknh = blacknh / poptotal,
            pasiannh = (asiannh + pacificnh) / poptotal,
            pothmultnh = (othernh + multracenh) / poptotal,
            pownhome = ownerocc / hutotal,
            p_65up = age65up / poptotal,
            p_0017 = ageunder18 / poptotal,
            sens_age = (age65up + ageunder18) / poptotal,
            pd_any = anydis / cdenom) %>%
  pivot_longer(names_to = "variable", values_to = "MEANRAW2", -rgn)

md_gee <- 
  tribble(~rgn, ~variable, ~MEANRAW2,
          "twin cities", "canopy_percent", ctu_list_raw$avgcanopy[1], 
          "twin cities", "canopy_percent2", ctu_list_raw$avgcanopy[1]
  )

metadata <- bg_growingshade_main %>%
  dplyr::group_by(type, name, variable, interpret_high_value, cc, ej, ph, cons) %>%
  dplyr::count() %>%
  dplyr::ungroup() %>%
  full_join(md1) %>%
  mutate(niceinterp = 
           case_when(interpret_high_value == "high_opportunity" ~ "Higher",
                     TRUE ~ "Lower"),
         nicer_interp = case_when(niceinterp == "Lower" ~ "Lower values = higher priority", 
                                  variable == "inverse_ndvi_uncultivated" ~ "Higher values = higher priority",
                                  variable == "inverse_ndvi_land" ~ "Higher values = higher priority",
                                  variable == "canopy_percent2" ~ "Higher values = higher priority",
                                  TRUE ~ "")) %>%
  full_join(acs_metadata %>%
              bind_rows(md_gee)) %>%
  mutate(MEANRAW = if_else(!is.na(MEANRAW2), MEANRAW2, MEANRAW)) %>%
  dplyr::select(-MEANRAW2, -rgn)

usethis::use_data(metadata, overwrite = TRUE)

```

## Highest priority for each block group

For storymap and to make database.

```{r}
highest_p <- function(x) {
  test <- enquo(x)
  
  bg_growingshade_main %>%
    filter(name %in% (metadata %>%
                        filter(!!test == 1)))
}

highest_p(ph)

highest_p <- function(group_var) {
  selectedvars <- metadata %>%
    filter(!!enquo(group_var) == 1) %>%
    .[,2]
  bg_growingshade_main %>% 
    filter(name %in% selectedvars$name) %>%
    group_by(bg_string) %>%
    summarise(MEAN = mean(weights_scaled, na.rm = F)) #set to false so that public health or ej doesnt get calculated if it is a nonres area
}

priority_summary_1 <-highest_p(ph) %>% rename(`Public health` = MEAN) %>%
  full_join(highest_p(cons) %>% rename(Conservation = MEAN)) %>%
  full_join(highest_p(ej) %>% rename(`Environmental justice` = MEAN)) %>%
  full_join(highest_p(cc) %>% rename(`Climate change` = MEAN)) %>%
  pivot_longer(names_to = "preset", values_to = "score", -bg_string) 

priority_summary <- priority_summary_1 %>%
  group_by(bg_string) %>%
  summarise(score = max(score, na.rm = T)) %>%
  left_join(priority_summary_1) %>%
  rename(highest_priority = preset) %>%
  rename(GEOID = bg_string)

```

highest priority all

```{r include=F, eval = F}

highest_p_all <- function(group_var) {
  selectedvars <- metadata %>%
    filter(!!enquo(group_var) == 1) %>%
    .[,2]
  bg_growingshade_main_allMN %>% 
    filter(name %in% selectedvars$name) %>%
    group_by(bg_string) %>%
    summarise(MEAN = mean(weights_scaled, na.rm = F))
}

priority_summary_1_all <-highest_p_all(ph) %>% rename(`Public health` = MEAN) %>%
  full_join(highest_p_all(cons) %>% rename(Conservation = MEAN)) %>%
  full_join(highest_p_all(ej) %>% rename(`Environmental justice` = MEAN)) %>%
  full_join(highest_p_all(cc) %>% rename(`Climate change` = MEAN)) %>%
  pivot_longer(names_to = "preset", values_to = "score", -bg_string) 

priority_summary_all <- priority_summary_1_all %>%
  pivot_wider(names_from = preset, values_from = score) %>%
  left_join(bg_growingshade_main_allMN %>%
              rename(scaled = weights_scaled,
                     raw = raw_value) %>%
              # ungroup() %>%
              dplyr::select(bg_string, variable, scaled, raw) %>%
              pivot_wider(names_from = variable, values_from = c(scaled, raw))) %>%
  arrange(bg_string) %>%
  rename(block_group_id_2010 = bg_string)



bg_geo %>%
  right_join(priority_summary_all, by = c("GEOID" = "block_group_id_2010")) %>%
  filter(!is.na(`Environmental justice`)) %>%
  ggplot() +
  geom_sf(aes(fill = `Environmental justice`), lwd = 0) +
  theme_minimal()

```

# Export data

```{r bg_shapefiles_for_mapping}

mn_bgs_raw <- bg_geo %>%
  right_join(wide_ctu_crosswalk) %>%
  full_join(bg_canopy %>% rename(GEOID = bg20)) %>%
  full_join(priority_summary) %>%
  full_join(priority_summary_1 %>%
              group_by(preset) %>% 
              # mutate(rank = rank(-score)) %>%
              # dplyr::select(-score) %>%
              pivot_wider(names_from = preset, values_from = score)#rank)
            %>% rename(GEOID = bg_string)) %>%
  mutate(avgcanopy = mean(canopy_percent, na.rm = T)) %>%
  dplyr::select(-STATEFP, -COUNTYFP, -TRACTCE, -BLKGRPCE, -NAMELSAD, -MTFCC, -FUNCSTAT, -INTPTLAT, -INTPTLON) %>%
  sf::st_as_sf() %>%
  sf::st_transform(4326) %>% 
  filter(!is.na(highest_priority)) %>% #don't want greater mn in here
  mutate(fancyname = case_when(substr(GEOID, 3, 5) == "053" ~ paste0("Hennepin County tract ", as.numeric(substr(GEOID, 6, 11))/100, ", block group ", as.numeric(substr(GEOID, 12, 12))),
                               substr(GEOID, 3, 5) == "003" ~ paste0("Anoka County tract ", as.numeric(substr(GEOID, 6, 11))/100, ", block group ", as.numeric(substr(GEOID, 12, 12))),
                               substr(GEOID, 3, 5) == "019" ~ paste0("Carver County tract ", as.numeric(substr(GEOID, 6, 11))/100, ", block group ", as.numeric(substr(GEOID, 12, 12))),
                               substr(GEOID, 3, 5) == "037" ~ paste0("Dakota County tract ", as.numeric(substr(GEOID, 6, 11))/100, ", block group ", as.numeric(substr(GEOID, 12, 12))),
                               substr(GEOID, 3, 5) == "123" ~ paste0("Ramsey County tract ", as.numeric(substr(GEOID, 6, 11))/100, ", block group ", as.numeric(substr(GEOID, 12, 12))),
                               substr(GEOID, 3, 5) == "139" ~ paste0("Scott County tract ", as.numeric(substr(GEOID, 6, 11))/100, ", block group ", as.numeric(substr(GEOID, 12, 12))),
                               substr(GEOID, 3, 5) == "163" ~ paste0("Washington County tract ", as.numeric(substr(GEOID, 6, 11))/100, ", block group ", as.numeric(substr(GEOID, 12, 12))),
                               TRUE ~ NA_character_)) 

# usethis::use_data(mn_bgs, overwrite = TRUE)
filter(mn_bgs_raw, GEOID == "270539800001") #for na people blocks priority summary is giving two results; should only be one
filter(priority_summary, GEOID == "270539800001")
filter(priority_summary, GEOID == "270030501071")

mncounties <- tigris::counties(state = "MN") %>%
  filter(COUNTYFP %in% c("003", "019", "037", "053", "123", "139", "163"))
metc_region <- mncounties %>% group_by(COUNTYFP) %>% summarise(geometry = sf::st_union(geometry)) %>%
  sf::st_simplify(dTolerance = 400) %>%
  sf::st_transform(4326)
usethis::use_data(metc_region, overwrite = TRUE)

```

# Simplify data for speed

```{r}
speed_up <- function(x, smooth){
  x %>%
    sf::st_transform(26915) %>%
    sf::st_simplify(dTolerance = smooth, preserveTopology = T) %>%
    sf::st_transform(4326)
  
}
# nhood_list <- nhood_list %>% st_make_valid() %>% st_simplify(dTolerance = 100) %>% st_as_sf()
ctu_list <- ctu_list_raw %>%
  sf::st_transform(4326)
usethis::use_data(ctu_list, overwrite = TRUE)

nhood_list <- nhood_list_raw %>% 
  speed_up(50)
usethis::use_data(nhood_list, overwrite = TRUE)

redline <- redline_raw %>% 
  speed_up(50)
usethis::use_data(redline, overwrite = TRUE)

# lakes <- river_lake_all %>%
#   filter(SYSTEM %in% c("Lake"),
#          AREA_ACRES > 10) %>% #these rivers are boundaries
#   sf::st_transform(26915) %>%
#   st_union() %>%
#   st_buffer(-10) %>%
#   # smoothr::smooth(method = "ksmooth") %>%
#   sf::st_simplify(dTolerance = 50, preserveTopology = F) #Thereâ€™s also a parameter preserveTopology which, when set to TRUE, makes sure that polygons are not reduced to lines or even removed, or that inner holes in them are removed during the simplification process.

# temp <- tempfile()
# download.file("https://resources.gisdata.mn.gov/pub/gdrs/data/pub/us_mn_state_dot/trans_airports/gpkg_trans_airports.zip", destfile = temp)
# airports <- sf::read_sf(unzip(temp, "trans_airports.gpkg"))  %>%
#   st_buffer(dist = .$RUNWAY_WID) %>%
#   st_union() %>%
#   # ggplot() + geom_sf()
#   # sf::st_simplify(dTolerance = 25, preserveTopology = F) %>%
#   sf::st_transform(4326) 


mn_bgs <- mn_bgs_raw %>% 
  # if I want to remove lakes; I don't love them removed tbh
  # st_transform(26915) %>%
  # st_erase(lakes) %>% 
  # st_erase(airports) %>%
  sf::st_simplify(dTolerance = 25, preserveTopology = T) %>%
  sf::st_transform(4326) %>%
  filter(!is.na(GEOID)) #%>%
# filter(GEOID != "270539800001") #remove airport
usethis::use_data(mn_bgs, overwrite = TRUE)


# leaflet::leaflet() %>%
#   leaflet::addPolygons(data = mn_bgs) %>%
#   leaflet::addPolygons(data = mn_bgs5, color = "red")
# object.size(mn_bgs) / 1e5
# object.size(mn_bgs5) / 1e5

bg_growingshade_main <- bg_growingshade_main %>%
  dplyr::select(bg_string, name, weights_scaled, raw_value) %>%
  filter(!is.na(bg_string))
usethis::use_data(bg_growingshade_main, overwrite = TRUE)

# eab <- eab %>% dplyr::select(geometry)
# usethis::use_data(eab, overwrite = TRUE)

# object.size(eab2) / 1e5
# object.size(eab) / 1e5
# # ggplot() +
# #   geom_sf(data = ctu_list) +
# #   geom_sf(data = ctu_list2, col = "blue", fill = NA)

```

# block group issues

the current watermask in gee is only for metcouncil area; this dataset probably works for rest of state: <https://gisdata.mn.gov/dataset/water-national-hydrography-data> (but need something from WI in there too)

would want to focus only on residential area or city boundaries; ag land has different purposes/uses/challenges/sustainability goals.

very slow when showing block groups across entire state

-- options: focus on statistical areas; some of this won't be super useful either since ag land focus on areas where population density is above some threshold
