---
title: "Growing Shade methods"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: 
  github_document:
    toc: true
always_allow_html: true
urlcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, message = F, warning = F,
                      cache = TRUE,
                      cache.path = "cache/")
library(tidyverse)
library(tigris)
library(sf)
# source("packages_global.R")

st_erase = function(x, y) st_difference(x, st_union(st_combine(y)))
`%not_in%` <- Negate(`%in%`)

```


# block group issues

the current watermask in gee is only for metcouncil area; this dataset probably works for rest of state: https://gisdata.mn.gov/dataset/water-national-hydrography-data (but need something from WI in there too)

would want to focus only on residential area or city boundaries; ag land has different purposes/uses/challenges/sustainability goals. 

very slow when showing block groups across entire state

--
options:
focus on statistical areas; some of this won't be super useful either since ag land
focus on areas where population density is above some threshold

# Introduction

The Growing Shade Project couples remote sensing data and demographic data to create insights about the intersection between the natural environment and people in real-time. 

Because there are several steps which must be done in order, this document lays those steps out logically. 

These are the files that must be in the data folder:

- mn_tracts.rda
- eva_data_main.rda
- metadata.rda
- ctu_list.rda
- nhood_list.rda
- redline.rda
- trans_stops.rda
- ctu_crosswalk.rda
- nhood_crosswalk.rda
- metc_region.rda



## Redlining shapefile

HOLC Redlining; this data was originally in equity considerations dataset, but that data uses old 2010 geographies, so need to actually get the data. 

Remove open water. "all non residential" 

```{r holc}
## holc  ---------------
# ftp://ftp.gisdata.mn.gov/pub/gdrs/data/pub/us_mn_state_metc/plan_historic_holc_appraisal/gpkg_plan_historic_holc_appraisal.zip
temp <- tempfile()
download.file("ftp://ftp.gisdata.mn.gov/pub/gdrs/data/pub/us_mn_state_metc/plan_historic_holc_appraisal/gpkg_plan_historic_holc_appraisal.zip",
  destfile = temp
)
# holc <- sf::read_sf(unzip(temp, "plan_historic_holc_appraisal.gpkg")) %>%
#   group_by(HSG_SCALE) %>% 
#   summarise() %>% st_transform(26915) %>%
#   st_intersection(bg_geo %>% dplyr::select(GEOID) %>% st_transform(26915) %>% st_buffer(-10)) %>%
#   mutate(area = as.numeric(st_area(.))) %>%
#   st_drop_geometry() %>%
#   filter(HSG_SCALE %in% c("Definitely Declining", "Still Desirable", "Hazardous", "Best")) %>%
#   pivot_wider(names_from = HSG_SCALE, values_from = area) %>%
#   left_join(bg_geo %>% dplyr::select(GEOID) %>% mutate(area = as.numeric(st_area(.)))) %>%
#   mutate(SUM = rowSums(across(c(`Definitely Declining`:Hazardous)), na.rm = T)) %>%
#   mutate(across(`Definitely Declining`:`Hazardous`, ~.x / (SUM))) %>%
#   as_tibble() %>%
#   rename(holc_pred = Hazardous) %>%
#   dplyr::select(GEOID, holc_pred) %>%
#     drop_na()

redline_raw <- sf::read_sf(unzip(temp, "plan_historic_holc_appraisal.gpkg")) %>%
  filter(HSG_SCALE == "Hazardous") %>% # | HSG_SCALE == "Definitely Declining") %>%
  sf::st_union() %>%
  sf::st_transform(4326)

fs::file_delete("plan_historic_holc_appraisal.gpkg")
```

# Process geographies

## Get geographies

First we need to fetch various raw files to get geographic files

### Census block groups

Most data is shown at the census block group level. We are using 2020 era census geographies. 

```{r census-geography}
bg_geo_2010 <- tigris::block_groups(state = "MN", 
                                    county = c("Anoka", "Carver", "Dakota", "Hennepin", "Ramsey", "Scott", "Washington"),
                                    year = 2011) %>%
  mutate(GEO_NAME = GEOID)

bg_geo <- tigris::block_groups(state = "MN", year = 2020) %>%
  bind_rows(tigris::block_groups(state = "WI", county = c("Pierce", "Polk", "St. Croix"), year = 2020)) %>%
  sf::st_transform(4326) %>%
  mutate(GEO_NAME = GEOID) #%>%
  # filter(str_detect(GEO_NAME, "27003|27019|27037|27053|27123|27139|27163"))
  # mutate(Shape_Area = as.numeric(st_area(.)))
# sf::st_write(bg_geo, "/Users/escheh/Documents/GitHub/planting.shade/storymap-info/shapefiles/bg_geo.shp", append = FALSE)

```

### Neighborhoods and city levels

Since we're going to be making a map which shows census tracts, ctus, or neighborhoods depending on the user input, do the following to make a crosswalk relating block groups to the city and neighborhood levels:

- get geography of neighborhoods and cities
 - find the centroid and zoom level of area (for reactive zooming, if I want to re-implement that)

```{r ctu-nhood-geo}
# find centroid of geographies
find_centroid <- function(x, ...) {
  points <- x %>%
    mutate(zoom = case_when(Shape_Area < 1e6 ~ 15,
                            Shape_Area < 1e8 ~ 13,
                            Shape_Area < 1e9 ~ 12,
                            TRUE ~ 11)) %>%
    st_transform(26915) %>%
    st_centroid() %>%
    st_transform(4326) %>%
    dplyr::select(!!!quos(...), geometry, zoom) %>%
    mutate(lat = unlist(map(.$geometry,1)),
           long = unlist(map(.$geometry,2))) %>%
    sf::st_drop_geometry()
  geos <- x %>%
    dplyr::select(!!!quos(...), city, geometry) %>%
    st_transform(4326)
  combo <- full_join(geos, points) %>%
    arrange(!!!(quos(...))) 
  return(combo)
}


### neighborhoods -----------
#st paul here: https://information.stpaul.gov/City-Administration/District-Council-Shapefile-Map/dq4n-yj8b
#minneap here: https://opendata.minneapolismn.gov/datasets/communities/explore?location=44.970861%2C-93.261718%2C12.85
#brooklyn park here: but no dl: https://gis.brooklynpark.org/neighborhoodinfo/

minneap <- read_sf("../data-raw/minneapolis communities/Minneapolis_Communities.shp") %>%
  rename(GEO_NAME = CommName) %>%
  mutate(Shape_Area = as.numeric(st_area(.))) %>%
  mutate(city = "Minneapolis")

stpaul <- read_sf("../data-raw/stpaul communities/geo_export_0c076f52-d6ff-4546-b9fa-bd9980de6e8a.shp") %>%
  mutate(Shape_Area = as.numeric(st_area(.))) %>%
  rename(GEO_NAME = name2) %>%
  mutate(city = "St. Paul") %>%
  mutate(GEO_NAME = case_when(GEO_NAME == "CapitolRiver Council" ~ "Downtown",
                              GEO_NAME == "Thomas-Dale/Frogtown" ~ "Frogtown",
                              GEO_NAME == "West Side Community Organization" ~ "West Side",
                              GEO_NAME == "West 7th Federation/Fort Road" ~ "West 7th-Fort Road",
                              GEO_NAME == "Highland" ~ "Highland Park",
                              GEO_NAME == "Summit Hill Association" ~ "Summit Hill",
                              GEO_NAME == "Eastview-Conway-Battle Creek-Highwood Hills" ~ "Battle Creek-Conway-Eastview-Highwood Hills",
                              GEO_NAME == "The Greater East Side" ~ "Greater East Side",
                              GEO_NAME == "Como" ~ "Como Park",
                              TRUE ~ GEO_NAME))

nhood_geo <- bind_rows(minneap, stpaul) #%>%
  # find_centroid(., GEO_NAME)

#### ctus -----------
temp <- tempfile()
temp2 <- tempfile()
download.file(
  "https://resources.gisdata.mn.gov/pub/gdrs/data/pub/us_mn_state_metc/bdry_metro_counties_and_ctus/shp_bdry_metro_counties_and_ctus.zip",
  destfile = temp
)
unzip(zipfile = temp, exdir = temp2)
list.files(temp2)

ctu_geo <- sf::read_sf(paste0(temp2, pattern = "/CTUs.shp")) %>%
  dplyr::select(CTU_NAME, Shape_Area) %>%
  add_column(city = "doesn't matter") %>%
  # find_centroid(., CTU_NAME) %>%
  dplyr::select(-city) %>%
  rename(GEO_NAME = CTU_NAME) 

files <- list.files(temp2, full.names = T)
file.remove(files)

```

- Then make a crosswalk which relates block groups into neighborhoods and cities. For this step, it is useful to remove major river features (boundaries around rivers often are poorly aligned, removing rivers makes generating the crosswalk much cleaner)

```{r ctu-nhood-crosswalk}
temp <- tempfile()
download.file("ftp://ftp.gisdata.mn.gov/pub/gdrs/data/pub/us_mn_state_metc/water_lakes_rivers/gpkg_water_lakes_rivers.zip", destfile = temp)

river_lake_all <- sf::read_sf(unzip(temp, "water_lakes_rivers.gpkg")) 

# river layer to erase major boundary rivers-------
river_lake_buffer <- river_lake_all %>%
  filter(NAME_DNR %in% c("Mississippi", "Minnesota", "St. Croix")) #%>% #these rivers are boundaries


# fxns to make easy -----
# find crosswalks
find_crosswalks <- function(x) {
  crosswalk <- x %>%
  st_transform(26915) %>%
  st_buffer(-150) %>% #buffer the perimeter of the geography
  st_erase(river_lake_buffer %>%
             st_buffer(200) %>% #buffer out rivers
             st_union() %>% 
             st_buffer(0)) %>% 
  st_intersection(bg_geo %>% 
                    dplyr::select(GEOID) %>%
                    rename(tract_id = GEOID) %>%
                    st_transform(26915)) %>%
  st_drop_geometry()
    
  return(crosswalk)
}

ctu_crosswalk <- find_crosswalks(ctu_geo) %>%
  mutate(flag = case_when(GEO_NAME == "Blakeley Twp." & tract_id != "271390813001" ~ "remove", #minnesota river is squirrely
                   TRUE ~ "keep")) %>%
  filter(flag != "remove") %>% 
  dplyr::select(-flag)
nhood_crosswalk <- find_crosswalks(nhood_geo)

# test <- "Hilltop"
# bg_geo %>%
#   right_join(ctu_crosswalk %>% filter(GEO_NAME == test),
#              by = c("GEOID" = "tract_id")) %>%
#   ggplot()+
#   geom_sf(data = filter(ctu_geo, GEO_NAME ==test), fill = "blue", alpha =.1, color = "blue")+
#   # geom_sf(data = (bg_geo %>%
#   #                   right_join(filter(ctu_crosswalk, tract_id =="271390813001"),
#   #                              by = c("GEOID" = "tract_id"))), fill = "red", alpha =.1, color = "red")+
#   geom_sf(fill = NA, lwd = 2)
# 
# test <- "The Greater East Side"
# bg_geo %>%
#   right_join(nhood_crosswalk %>% filter(GEO_NAME == test),
#              by = c("GEOID" = "tract_id")) %>%
#   ggplot()+
#   geom_sf(data = filter(nhood_geo, GEO_NAME ==test), fill = "blue", alpha =.1, color = "blue")+
#   geom_sf(fill = NA, lwd = 2)


wide_ctu_crosswalk_1 <- ctu_crosswalk %>%
  group_by(tract_id) %>%
  count() %>%
  left_join(ctu_crosswalk) %>%
  add_column(cities = 999) %>%
  dplyr::select(tract_id, GEO_NAME, cities, n) %>%
  # spread(cities, GEO_NAME)
  pivot_wider(names_from = cities, values_from = GEO_NAME, values_fn = list) %>%
  unnest_wider(`999`) 

wide_ctu_crosswalk <- wide_ctu_crosswalk_1 %>%
  mutate(jurisdiction = paste(`...1`, `...2`, `...3`, `...4`,# `...5`, 
                              # `...6`, `...7`,
                              sep = ", ")) %>%
  dplyr::select(tract_id, jurisdiction) %>%
  mutate(jurisdiction = str_replace(jurisdiction, ", NA", ""),
         jurisdiction = str_replace(jurisdiction, ", NA", ""),
         jurisdiction = str_replace(jurisdiction, ", NA", ""),
         jurisdiction = str_replace(jurisdiction, ", NA", ""),
         jurisdiction = str_replace(jurisdiction, ", NA", ""),
         jurisdiction = str_replace(jurisdiction, ", NA", ""),
         jurisdiction = str_replace(jurisdiction, ", NA", "")) %>%
  rename(GEOID = tract_id)

usethis::use_data(ctu_crosswalk, overwrite = TRUE)
usethis::use_data(nhood_crosswalk, overwrite = TRUE)
usethis::use_data(wide_ctu_crosswalk, overwrite = TRUE)

```

### Calculate land area

From the various geographic files, remove all water features and calculate the land area. Doing this step is necessary in order to figure out tree canopy cover on land. Unfortunately, the "aland" variable from census block groups is *less* useful here, because neighborhoods and cities don't always respect block group boundaries.

```{r calc-land-area}
calc_land_area <- function(x){
  x %>%
    st_transform(26915) %>%
    st_buffer(0) %>%
    st_erase(river_lake_all %>%
             st_union() %>%
             st_buffer(0)) %>%
    mutate(ALAND = as.numeric(st_area(.)))
}

ctu_land <- calc_land_area(ctu_geo)
nhood_land <- calc_land_area(nhood_geo)
bg_land_geo <- calc_land_area(bg_geo)

```

# Remote sensing data 

These items come out of Google Earth Engine analyses. Some files need to be created/exported (and then imported into GEE), and all GEE exports need to be pulled in to this code.

```{r create-gee_assets}
# ######
# # Create a gridded area across the region to calibrate sentinel tree cover with 1m2 land cover tree data
# #####
# wholearea <- metc_region %>%
#   summarise(st_union(.))
# 
# # make a equal area grid; there are 704 tracts, so I want to make at least 1000 grids I think?
# g = st_make_grid(wholearea,
#                  n = c(36, 36)) %>% 
#   st_intersection(wholearea) 
# 
# geometry = st_sfc(lapply(1:length(g), function(x) st_geometrycollection()))
# df <- st_sf(id = 1:length(g), geometry = g)
# 
# # ggplot() +
# #   geom_sf(data = wholearea) +
# #   geom_sf(data = df,
# #           fill = "transparent")
# 
# sf::st_write(df, "~/Documents/GitHub/planting.shade/storymap-info/shapefiles/metc_grid.shp", append = FALSE)
# 

# #########
# #update to 2020 geography
# ########
# MN_counties <- c("Anoka", "Carver", "Dakota", "Hennepin", "Ramsey", "Scott", "Washington")
# 
# block_group2020 <- tigris::block_groups(
#   year = 2021,
#   state = "MN",
#   county = MN_counties,
#   class = "sf"
# ) %>%
#   dplyr::select(GEOID)
# sf::st_write(block_group2020, "~/Documents/GitHub/planting.shade/storymap-info/blockgroups2020.shp", append = FALSE)
# 
```


## Calculate and calibrate tree canopy coverage 

For some good reasons we are going to use data from 2020 for the tree canopy coverage. But since Sentinel has a 10 meter squared pixel size, this is larger than a lot of trees. In exploring the data, it appears as if the canopy coverage from Sentinel is about two times higher than what it should be (based on aerial imagery). However, this does make sense, because Sentinel is likely saying that a 10x10m pixel has a tree, even if that tree doesn't cover the whole area. In essence, it's telling us where land is covered at least half by trees. But we can refine this further!! Let's calibrate with the outdated UMN 1 meter squared land use file. 

Use UMN TC 1m2 land use where trees = coniferous trees, deciduous trees, and forested wetland (this last category is a new addition to the tree acres!). 

Calibration coeff is 0.885246, meaning that sentinel sees about 11% more trees; or detects area with at least 89% tree canopy coverage. Sentinel sees 1000 acres, UMN sees more like 885 (890) acres. 

```{r, calibrate-tree-cover}
calibrate_trees <- read_csv("../data-raw/TreeAcresCART/UMNTreeAcres_metcgrid_scale1_year2021.csv") %>% 
  rename(umn = `1`) %>%
  full_join(read_csv("../data-raw/TreeAcresCART/TreeAcres_metcgrid_year2021.csv") %>%
              rename(sentinel = `1`),
            by = 'id')
#if do equal area grid r2 = 0.9343173; calib = 0.6123283
# cor.test(~ umn + sentinel,
#          data = calibrate_trees)
# cor.test(~ umn + I(sentinel^2),
#          data = calibrate_trees)

calibrate_lm <- (lm(umn ~ sentinel, data = calibrate_trees))
calibrate_lm2 <- (lm(umn ~ 0 + sentinel, data = calibrate_trees))
calibrate_lm3 <- (lm(umn ~ I(sentinel ^ 2), data = calibrate_trees))
calibrate_lm4 <- (lm(log(umn) ~ sentinel, data = calibrate_trees))
anova(calibrate_lm, calibrate_lm2, calibrate_lm3, calibrate_lm4) # the middle model is best!

# AIC(calibrate_lm); AIC(calibrate_lm2); AIC(calibrate_lm3)
anova(calibrate_lm, calibrate_lm2)
anova(calibrate_lm2, calibrate_lm3)

summary(calibrate_lm2)$r.squared # r2
summary(calibrate_lm2)$coefficients[,4] # p-value

calib_coeff <- summary(calibrate_lm2)$coefficients[,1] # coefficient
calib_coeff

calibrate_trees %>%
  ggplot(aes(x = (umn), y = (sentinel * calib_coeff))) +
  geom_point(alpha = .5) +
  geom_abline(slope=1, intercept=0, col = 'blue', lwd = 2) +
  # geom_smooth(method = "lm", fill = NA)+
  theme_minimal()  +
  # councilR::theme_council()
  labs( x = "UMN tree acres in grid", y = "Sentinel tree acres in grid",
        title = "calibrated")
```

## Process tree canopy cover at various geographies

```{r tree-canopy-rawdata}
bg_canopy <- 
read_csv("./TreeAcresCART/TreeAcres_blockgroups2020_year2021.csv",
                   col_types = cols(.default = "d", GEOID = "c")) %>%
  replace(is.na(.), 0) %>%
  left_join(sf::st_drop_geometry(bg_land_geo), by = c("GEOID" = "GEOID")) %>%
  transmute(bg20 = GEOID, 
            treeacres = `1`,
            landacres = ALAND / 4046.86,
            canopy_percent = treeacres / landacres * calib_coeff) #use calibration coefficient

## ctu canopy ----
canopy_ctu <- read_csv("./TreeAcresCART/TreeAcres_ctus_year2021.csv",
                   col_types = cols(.default = "d", CTU_NAME = "c")) %>%
  mutate(CTU_NAME = if_else(CTU_NAME == "Credit River Twp.", "Credit River", CTU_NAME)) %>%
  left_join(ctu_land, by = c("CTU_NAME" = "GEO_NAME")) %>%
  transmute(GEO_NAME = CTU_NAME, 
            treeacres = `1`,
            landacres = ALAND / 4046.86,
            canopy_percent = treeacres / landacres * calib_coeff) 

## nhood canopy ----
canopy_nhood <- read_csv("./TreeAcresCART/TreeAcres_neighborhoods_year2021.csv",
                   col_types = cols(.default = "d", GEO_NAME = "c")) %>%
  mutate(GEO_NAME = case_when(GEO_NAME == "CapitolRiver Council" ~ "Downtown",
                              GEO_NAME == "Thomas-Dale/Frogtown" ~ "Frogtown",
                              GEO_NAME == "West Side Community Organization" ~ "West Side",
                              GEO_NAME == "West 7th Federation/Fort Road" ~ "West 7th-Fort Road",
                              GEO_NAME == "Highland" ~ "Highland Park",
                              GEO_NAME == "Summit Hill Association" ~ "Summit Hill",
                              GEO_NAME == "Eastview-Conway-Battle Creek-Highwood Hills" ~ "Battle Creek-Conway-Eastview-Highwood Hills",
                              GEO_NAME == "The Greater East Side" ~ "Greater East Side",
                              GEO_NAME == "Como" ~ "Como Park",
                              TRUE ~ GEO_NAME)) %>%
  left_join(nhood_land, by = c("GEO_NAME" = "GEO_NAME")) %>%
  transmute(GEO_NAME = GEO_NAME, 
            treeacres = `1`,
            landacres = ALAND / 4046.86,
            canopy_percent = treeacres / landacres * calib_coeff) %>%
  full_join(read_csv("../data-raw/TreeAcresCART/UMNTreeAcres_neighborhoods_scale1_year2021.csv") %>%
                mutate(GEO_NAME = case_when(GEO_NAME == "CapitolRiver Council" ~ "Downtown",
                              GEO_NAME == "Thomas-Dale/Frogtown" ~ "Frogtown",
                              GEO_NAME == "West Side Community Organization" ~ "West Side",
                              GEO_NAME == "West 7th Federation/Fort Road" ~ "West 7th-Fort Road",
                              GEO_NAME == "Highland" ~ "Highland Park",
                              GEO_NAME == "Summit Hill Association" ~ "Summit Hill",
                              GEO_NAME == "Eastview-Conway-Battle Creek-Highwood Hills" ~ "Battle Creek-Conway-Eastview-Highwood Hills",
                              GEO_NAME == "The Greater East Side" ~ "Greater East Side",
                              GEO_NAME == "Como" ~ "Como Park",
                              TRUE ~ GEO_NAME))) %>%
  mutate(umn_canopy = `1`/landacres)

canopy_nhood %>%
  ggplot(aes(x = canopy_percent, y = umn_canopy)) + geom_point()

```


- process GEE code to link canopy with geography
  - GEE data is in repo "users/ehe/MetCoucil/GrowingShade_CanopyCoverage"
  - https://code.earthengine.google.com/a0da66053ecb26b668df4297c4ebed59

- bind everything together for city and nhood

```{r tree-canopy-summaries}
tree_summary <- function(.geo_file,
                         .crosswalk_file,
                         .canopy_file) {
  
  .geo_file %>%
    full_join(
      .crosswalk_file %>%
        left_join(bg_canopy %>%
                rename(tract_id = bg20),
              by = "tract_id") %>%
        group_by(GEO_NAME) %>%
        summarise(min = round(min(canopy_percent)*100, 1),
              max = round(max(canopy_percent)*100, 1),
              ntracts = n())) %>%

  full_join(.canopy_file) #%>%
  # arrange(!!!.group_factor, GEO_NAME)# %>%
  # # st_transform(4326) %>%
  # group_by(!!.group_factor) %>%
  # mutate(avgcanopy = (sum(treeacres) / sum(landacres) * calib_coeff))
}

nhood_list_raw <- tree_summary(.geo_file = nhood_geo,
                         .crosswalk_file = nhood_crosswalk,
                         .canopy_file = canopy_nhood) %>%
  arrange(city, GEO_NAME) %>%
  # st_transform(4326) %>%
  group_by(city) %>%  
  mutate(avgcanopy = (sum(treeacres) / sum(landacres) * calib_coeff))

ctu_list_raw <- tree_summary(.geo_file = ctu_geo,
                         .crosswalk_file = ctu_crosswalk,
                         .canopy_file = canopy_ctu) %>%
  arrange(GEO_NAME) %>%
  mutate(avgcanopy = (sum(treeacres) / sum(landacres) * calib_coeff))
  
# sf::st_write(ctu_list, "~/Documents/GitHub/planting.shade/storymap-info/shapefiles/ctu_list.shp", append = FALSE)
```



## Greenness (NDVI) Data

We do this for all land (no water!) and non-cultivated land (excluding crops/ag land).


```{r ndvi_bgs}
ndvi_uncultivated <- 
  read_csv("./TreeAcresCART/uncultivatedNDVI_blockgroups2020_year2021.csv",
                    na = "No data",
                       col_types = cols(GEOID = "c", `system:index` = "c", Year = 'd',  `.geo` = 'c')) %>%
  rename(GEOID = GEOID)

ndvi_allland <- 
  read_csv("../data-raw/TreeAcresCART/landNDVI_blockgroups2020_year2021.csv",
                    na = "No data",
                       col_types = cols(GEOID = "c", `system:index` = "c", Year = 'd',  `.geo` = 'c')) %>%
  rename(GEOID = GEOID)
  
  # read_csv("../data-raw/TreeAcres/meanNDVI_mnwi_blockgroups_year2021.csv",
  #                   na = "No data",
  #                      col_types = cols(GEOID = "c", `system:index` = "c", Year = 'd', ndvi = 'd', `.geo` = 'c')) %>%
  # dplyr::select(-`system:index`, -.geo, -Year)
bg_ndvi <- ndvi_uncultivated %>%
  dplyr::select(GEOID, ndvi_uncultivated) %>%
  full_join(ndvi_allland %>%
  dplyr::select(GEOID, ndvi_land)) %>%
    rename(bg20 = GEOID)
```

# Demographic variables

Demographic variables come from various places.

## Decennial census

Has information about race and total population numbers. 

```{r decennial-census-race}
temp <- tempfile()
download.file("https://resources.gisdata.mn.gov/pub/gdrs/data/pub/us_mn_state_metc/society_census2020population/xlsx_society_census2020population.zip",
  destfile = temp
)
census_race <- readxl::read_xlsx(unzip(temp, "Census2020PopulationBlockGroup.xlsx")) %>%
  janitor::clean_names() %>%
  transmute(
    bg20 = geog_unit,
    poptotal = poptotal,
         pblacknh = blacknh / poptotal,
         pasiannh = (asiannh + pacificnh) / poptotal,
         phisppop = hisppop / poptotal,
         pamindnh = amindnh / poptotal,
        pothmultnh = (multracenh + othernh) / poptotal,
         pbipoc = 1 - (whitenh / poptotal),
    
    poptot_mc = poptotal,
    hutot_mc = hhtotal
  ) 

fs::file_delete("./Census2020PopulationBlockGroup.xlsx")

# filter(census_race, (bg20 == "270539800001"))

```

## ACS data

This is where most variables come from. ACS data now uses 2020 geographies!

```{r acsdata}
# in most cases, downloading the acs data will be appropriate since other varibales will come from equity considerations data. In the meantime, equity considerations uses old geographies, so is not appropriate here. 
temp <- tempfile()
download.file("https://resources.gisdata.mn.gov/pub/gdrs/data/pub/us_mn_state_metc/society_census_acs/xlsx_society_census_acs.zip",
  destfile = temp
)

# tract variables of interest; some variables only exist at tract level
acs_tractsonly <- readxl::read_xlsx(unzip(temp, "CensusACSTract.xlsx")) %>%
  janitor::clean_names()
tract_acs <-  acs_tractsonly %>%
  transmute(tr20 = geog_unit,
            pd_any = anydis / cdenom,
            povdenom = povdenom)

fs::file_delete("CensusACSTract.xlsx")

# block group variables of interest
# acs <- readxl::read_xlsx(unzip(temp, "CensusACSBlockGroup.xlsx")) %>%
#   janitor::clean_names() 
acs <- read_csv("./20205_blockgroup.csv") %>%
  janitor::clean_names()

bg_acs <- acs %>% 
  transmute(
    bg20 = as.character(geog_unit),
    ppov185 = pov185rate,
    mdhhincnow = medianhhinc, #medianhhi
    pownhome = homeownerrate, #homeownpct,
    
    #get some variables to replace census zeros where needed
        pblacknh_acs = blacknh / poptotal,
         pasiannh_acs = (asiannh + pacificnh) / poptotal,
         phisppop_acs = hisppop / poptotal,
         pamindnh_acs = amindnh / poptotal,
        pothmultnh_acs = (multracenh + othernh) / poptotal,
        pbipoc_acs = 1 - (whitenh / poptotal),
         p_0017_acs = ageunder18 / poptotal,
         p_65up_acs = age65up / poptotal,
         sens_age_acs = p_0017_acs + p_65up_acs,
    
    #new to replace old equity considerations data
    phhi_qntl1 = phhi_qntl1,
    pwk_nowork = pwk_nowork) %>%
  
  mutate(tr20 = substr(bg20, 1, 11)) %>%
  full_join(tract_acs)

```



## Equity considerations data

This dataset has been *replaced* because it does not have current geographies. 

```{r equity-considerations-data}
# equity_bg <- read_csv("/Volumes/shared/CommDev/Research/Research/EquityConsiderationsData/2_OutputData/CSV/Release_20210225/EquityConsiderationsBlockGroups.csv",
#                    col_types = cols( .default = "?", BG10 = "c")) %>%
#   janitor::clean_names() 
# equity_considerations <- equity_bg %>%
#   dplyr::select(bg10,
#          prim_flood,
#          # avg_temp, #from google earth engine
#          # phhi_qntl1, #this can be updated with new acs data
#          green_roof,
#          env_cancer, #ej screen has NOT been updated, so use old data here
#          luse_green,
#          tr_ej,
#          # holc_pred, holc_pgrn, holc_pblu, holc_pylw, #updated with raw data
#          # pwk_nowork, #updated with new acs data
#          # poptot_mc, #from census 2020
#          # hutot_mc #from census 2020
#          ) 
```

There are several variables which Matt processed in advance of an equity considerations release for me with new geographies:

```{r matt-data}
matt_data <- 
  readxl::read_xlsx("./EJSCREEN_OLD_BG20.xlsx") %>%
  transmute(bg20 = BG20,
            env_cancer = ENV_CANCER) %>%
  
  full_join(
readxl::read_xlsx("./HOLC_BG20.xlsx") %>%
  transmute(bg20 = BG20,
            holc_pred = HOLC_4_RED)) %>%

  full_join(
readxl::read_xlsx("./CLIMATE_BG20.xlsx") %>%
  transmute(bg20 = BG20,
            avg_temp = AVG_TEMP,
            prim_flood = PRIM_FLOOD,
            green_roof = GREEN_ROOF
            ))

```



## Health data from CDC
- Enter in the console: `usethis::edit_r_environ()`
- When the `.Renviron` file comes up in the editor, type: `CDC_KEY="KEY GOES HERE, INSIDE QUOTES"`
- Save and close the `.Renviron` file.
- Hit Ctrl+Shift+F10 to restart R.

[PLACES: Local Data for Better Health, Census Tract Data 2021 release](https://chronicdata.cdc.gov/500-Cities-Places/PLACES-Local-Data-for-Better-Health-Census-Tract-D/cwsq-ngmh)

```{r health_bgs}
##########
# CDC health data
#########
# variable options are documented here: https://www.cdc.gov/places/measure-definitions/index.html
# api token: https://chronicdata.cdc.gov/profile/edit/developer_settings

library("RSocrata")
#metadata https://dev.socrata.com/foundry/chronicdata.cdc.gov/cwsq-ngmh

bg_health <- read.socrata(
  "https://chronicdata.cdc.gov/resource/cwsq-ngmh.json?$where=stateabbr in('MN', 'WI')",
  app_token = Sys.getenv("CDC_TOKEN"), 
  email     = "ellen.esch@metc.state.mn.us",
  password  = Sys.getenv("CDC_KEY")) %>% 
  rename(GEOID20 = locationname)

bg_health
names(bg_health)
levels(as.factor(bg_health$measure))

bg_health2 <- bg_health %>%
  filter(measure %in% c("Current asthma among adults aged >=18 years",
                        "Chronic obstructive pulmonary disease among adults aged >=18 years",
                        "Mental health not good for >=14 days among adults aged >=18 years",
                        "Physical health not good for >=14 days among adults aged >=18 years")) %>%
  dplyr::select(GEOID20, measureid, data_value) %>%
  mutate(data_value = as.numeric(data_value) / 100) %>% #change to fraction
  pivot_wider(names_from = measureid, values_from = data_value) %>%
  rename(tr20 = GEOID20)

```
# Combine all variables

Merge demographic and environmental data 

```{r combinedata}
bg_growingshade_data_allMN <- 
  
  #demographics
  census_race %>%
  full_join(bg_acs) %>%
  # filter(bg20 == "270531016003") %>%
  
  full_join(matt_data) %>% #equity_considerations
  full_join(bg_health2) %>%

  #environmental
  full_join(bg_canopy) %>%
  full_join(bg_ndvi) %>%
  
  #update some variables
  # filter(str_detect(bg10, "27003|27019|27037|27053|27123|27139|27163")) %>%
  mutate(tr20 = substr(bg20, 1, 11)) %>% #this is the tract id


  mutate(inverse_ndvi_uncultivated = ndvi_uncultivated,
         inverse_ndvi_land = ndvi_land,
         canopy_percent2 = canopy_percent,
         pop_density = poptot_mc / landacres,
         housing_density = hutot_mc / landacres) %>%
  rename(tract_string = bg20) %>%
  rowwise() %>%
  mutate(holc_pred = if_else(is.na(holc_pred), 0, holc_pred)) #%>%
  
    # deal witih some non residential blocks
  mutate(across(c(poptotal:pwk_nowork, pd_any:holc_pred, CASTHMA:PHLTH, pop_density:housing_density), ~ if_else(poptotal < 10, NA_real_, .x)),
         across(c(poptotal:pwk_nowork, pd_any:holc_pred, CASTHMA:PHLTH, pop_density:housing_density), ~ if_else(is.na(mdhhincnow), NA_real_, .x))) %>% 
  # mutate(across(c(pblacknh:pbipoc, phhi_qntl1, pwk_nowork, env_cancer, mdhhincnow), ~ if_else((is.nan(.x) | is.na(.x)) & poptotal == 0, NA_real_, .x))) %>%
  select(-c(pblacknh_acs:sens_age_acs))# %>% filter(bg20 == "270531016003")


#%>% #and for this project, I need to rename the tract variable
  # add_column(avg_temp = sample(100, size = nrow(bg_canopy), replace = TRUE),
             # env_cancer = sample(100, size = nrow(bg_canopy), replace = TRUE),
             # green_roof = sample(100, size = nrow(bg_canopy), replace = TRUE),
             # holc_pred = sample(100, size = nrow(bg_canopy), replace = TRUE),
             # luse_green = sample(100, size = nrow(bg_canopy), replace = TRUE),
             # phhi_qntl1 = sample(100, size = nrow(bg_canopy), replace = TRUE),
             # prim_flood = sample(100, size = nrow(bg_canopy), replace = TRUE),
             # pwk_nowork = sample(100, size = nrow(bg_canopy), replace = TRUE),
             # tr_ej = sample(100, size = nrow(bg_canopy), replace = TRUE)) %>%
  
bg_growingshade_data <- bg_growingshade_data_allMN %>%
  filter(str_detect(tract_string, "27003|27019|27037|27053|27123|27139|27163")) #just do metc region for now
```


Add some metadata. 

```{r make-metadata}
gs_data_codes <- tribble(~variable, ~name, ~type, ~interpret_high_value, ~cc, ~ej, ~ph, ~cons,
                          "pop_density", "Population density (persons / acre)", "people",  "high_opportunity", 0, 0, 0,  0,
                          "housing_density", "Housing unit density (units / acre)", "people",  "high_opportunity", 0, 0, 0,  0,
                          "ppov185",	"% people with income <185% of the poverty threshold", "dollar", "high_opportunity", 0, 1, 0, 0,
                          "prim_flood", "% developed acres in primary flood zone", "environment", "high_opportunity", 1, 0, 0, 0,
                          "pbipoc", "Race, % people of color", "people", "high_opportunity", 0, 1, 0, 0,
                          "p_0017", "Age, % under age 18", "people",  "high_opportunity", 0, 0, 0, 0, 
                          "p_65up", "Age, % age 65 or older", "people",  "high_opportunity", 0, 0, 0,  0,
                          "avg_temp", "Temperature on hot summer day", "environment",  "high_opportunity", 1, 0, 1, 0,
                          # "phhi_qntl1", "% households with annual income less than $35,000 (bottom quintile of households)", "people",  "high_opportunity", 0, 1, 0, 0,
                          # "green_roof", "Water holding potential of green roofs on commercial bldgs", "environment",  "high_opportunity", 
                          "env_cancer", "Lifetime cancer risk from air toxics", "health", "high_opportunity", 0, 0, 1,  0,

                          "ndvi_uncultivated", "Greenness, uncultivated land (2021 NDVI)", "environment", "low_opportunity", 1, 0, 1,  0,
                          "inverse_ndvi_uncultivated", "Greenness, uncultivated land (2021 NDVI) - for conservation", "environment", "high_opportunity", 0, 0, 0, 1,
                          
                          "ndvi_land", "Greenness, all land (2021 NDVI)", "environment", "low_opportunity", 1, 0, 1,  0,
                          "inverse_ndvi_land", "Greenness, all land (2021 NDVI) - for conservation", "environment", "high_opportunity", 0, 0, 0, 0,
                          
                          "tr_ej", "MPCA area of environmental justice concern", "environment", "high_opportunity", 0, 0, 0, 0,
                          "holc_pred", "% of block group's land acreage redlined", "environment", "high_opportunity", 0, 0, 0, 0,
                          "canopy_percent", "Tree canopy in 2021 (%)", "environment", "low_opportunity", 1, 0, 1, 0,
                          "canopy_percent2", "Tree canopy in 2021 (%) - for conservation", "environment", "high_opportunity", 0, 0, 0, 1,
                          "mdhhincnow", "Median household income", "dollar", "low_opportunity", 0, 0, 0, 0, #, 2015-2019 period (in 2019 dollars)
                          "sens_age", "Age, % under age 18 or 65+", "people", "high_opportunity", 0,0,1,0,
                          "pd_any", "Disability, % any disability", "people", "high_opportunity", 0, 0, 0, 0,
                          "pblacknh", "Race, % Black or African American", "people", "high_opportunity", 0, 0, 0, 0,
                          "pothmultnh", "Race, % Multiracial or other", "people", "high_opportunity", 0, 0, 0, 0,
                          "pasiannh", "Race, % Asian or Pacific Islander", "people", "high_opportunity", 0, 0, 0, 0,
                          "phisppop", "Race, % Hispanic or Latino", "people", "high_opportunity", 0, 0, 0, 0,
                          "pamindnh", "Race, % Indigenous", "people", "high_opportunity", 0, 0, 0, 0,
                          "pwk_nowork", "% of unemployed residents", "dollar", "high_opportunity", 0, 0, 0, 0, # age 16-64 who did not work in past 12 months
                          "pownhome", "% of residents who own their home", "dollar", "high_opportunity", 0,0,0,0,
                          "MHLTH", "Mental health not good for >=14 days among adults (%)", "health", "high_opportunity", 0,0,0,0,
                          "PHLTH", "Physical health not good for >=14 days among adults (%)", "health", "high_opportunity", 0,0,0,0,
                          "COPD", "Chronic obstructive pulmonary disease among adults (%)", "health", "high_opportunity", 0,0,0,0,
                          "CASTHMA", "Asthma among adults (%)", "health", "high_opportunity", 0,0,0,0
                          )
```

Standardize and re-scale variables so we can create equally weighted priority scores. Do *not* include spatial data at this point, it should be joined after summarizing to save computational time. 

```{r standardize-rescale}

bg_growingshade_main <- bg_growingshade_data %>%
  pivot_longer(names_to = "variable", values_to = "raw_value", -c(tract_string, tr20)) %>% #end the code after this line if you just want the reshaped data
  group_by(variable) %>%
  mutate(MEAN = mean(raw_value, na.rm = T),
         SD = sd(raw_value, na.rm = T),
         MIN = min(raw_value, na.rm = T),
         MAX = max(raw_value, na.rm = T),
         COUNT = as.numeric(sum(!is.na(raw_value))),
         z_score = (raw_value - MEAN)/SD) %>%
  
  full_join(gs_data_codes, by = 'variable') %>%
  
  # #we want high opportunity to be a high value, so this reorders those values if needed
  # mutate(opportunity_zscore = case_when(interpret_high_value == "high_opportunity" ~ z_score,
  #                                       interpret_high_value == "low_opportunity" ~ z_score * (-1),
  #                                         TRUE ~ NA_real_)) %>%
  
  #create nominal weights
  mutate(weights_nominal = case_when(interpret_high_value == "high_opportunity" ~ (raw_value - MIN) / (MAX - MIN) * 10,
                                     interpret_high_value == "low_opportunity" ~ 10 - (raw_value - MIN) / (MAX - MIN) * 10,
                                     TRUE ~ NA_real_)) %>%
  
  #Weights Standard Score
  mutate(weights_scaled = case_when(interpret_high_value == "high_opportunity" ~ pnorm(z_score) * 10,
                                    interpret_high_value == "low_opportunity" ~ (10 - pnorm(z_score) * 10),
                                    TRUE ~ NA_real_)) %>%
  
  #weights rank
  mutate(weights_rank = case_when(interpret_high_value == "high_opportunity" ~ min_rank(desc(weights_nominal)) / COUNT * 10,
                                  interpret_high_value == "low_opportunity" ~ min_rank(desc(weights_nominal)) / COUNT * 10,
                                  TRUE ~ NA_real_)) %>%
  
  # #rank
  mutate(overall_rank = case_when(interpret_high_value == "high_opportunity" ~ min_rank(desc(as.numeric(weights_nominal))),
                                  interpret_high_value == "low_opportunity" ~ min_rank(desc(as.numeric(weights_nominal))))) %>%
  # 
  #clean
  dplyr::select(-MEAN, -SD, -MIN, -MAX)  %>%
  full_join(wide_ctu_crosswalk %>% rename(tr20 = GEOID)) %>%
  filter(!is.na(name))

########
# save data
########
usethis::use_data(bg_growingshade_main, overwrite = TRUE)
gs_data_codes %>% arrange(type, name)%>% dplyr::select(type, name)



############
#all MN
##########
# #long data
bg_growingshade_main_allMN <- bg_growingshade_data_allMN %>%
  pivot_longer(names_to = "variable", values_to = "raw_value", -c(tract_string, tr20)) %>% #end the code after this line if you just want the reshaped data
  group_by(variable) %>%
  mutate(MEAN = mean(raw_value, na.rm = T),
         SD = sd(raw_value, na.rm = T),
         MIN = min(raw_value, na.rm = T),
         MAX = max(raw_value, na.rm = T),
         COUNT = as.numeric(sum(!is.na(raw_value))),
         z_score = (raw_value - MEAN)/SD) %>%
  
  full_join(gs_data_codes, by = 'variable') %>%
  
  # #we want high opportunity to be a high value, so this reorders those values if needed
  # mutate(opportunity_zscore = case_when(interpret_high_value == "high_opportunity" ~ z_score,
  #                                       interpret_high_value == "low_opportunity" ~ z_score * (-1),
  #                                         TRUE ~ NA_real_)) %>%
  
  #create nominal weights
  mutate(weights_nominal = case_when(interpret_high_value == "high_opportunity" ~ (raw_value - MIN) / (MAX - MIN) * 10,
                                     interpret_high_value == "low_opportunity" ~ 10 - (raw_value - MIN) / (MAX - MIN) * 10,
                                     TRUE ~ NA_real_)) %>%
  
  #Weights Standard Score
  mutate(weights_scaled = case_when(interpret_high_value == "high_opportunity" ~ pnorm(z_score) * 10,
                                    interpret_high_value == "low_opportunity" ~ (10 - pnorm(z_score) * 10),
                                    TRUE ~ NA_real_)) %>%
  #clean
  dplyr::select(-MEAN, -SD, -MIN, -MAX)  %>%
  # full_join(wide_ctu_crosswalk %>% rename(tr20 = GEOID)) %>%
  filter(!is.na(name))


```

# Create independant files for export

## Regional averages
Create some regional averages. While the average values for the block groups are needed to create zscores, those averages are not the regional averages. Ex average median income of block groups might be 60,000 but the regional average might be lower if there are more people living in ares with lower income. 


```{r regional-averages}
# ########
# # create metadata
# #########
md1 <- bg_growingshade_main %>% 
  group_by(variable) %>% 
  summarise(MEANRAW = mean(raw_value, na.rm = T),
            MEANSCALED = mean(weights_scaled, na.rm = T))

acs_metadata <-
acs_tractsonly %>% #use tracts becuase it has info about disability
    filter(str_detect(geoid, "27003|27019|27037|27053|27123|27139|27163"),
           year == 2020) %>% #just do metc region for now
  dplyr::select(geoid, poptotal:pphother) %>%
  pivot_longer(names_to = "variable", values_to = "values", -geoid) %>%
  group_by(variable) %>%
  summarise(SUM = sum(values, na.rm = T)) %>%
  pivot_wider(names_from = variable, values_from = SUM) %>%
  transmute(rgn = "twin cities",
            ppov185 = (povertyn + poverty150 + pov150_185) / povdenom,
            pbipoc = (poptotal - whitenh) / poptotal,
            pamindnh = (amindnh) / poptotal,
            phisppop = hisppop / poptotal,
            pblacknh = blacknh / poptotal,
            pasiannh = (asiannh + pacificnh) / poptotal,
            pothmultnh = (othernh + multracenh) / poptotal,
            pownhome = ownerocc / hutotal,
            p_65up = age65up / poptotal,
            p_0017 = ageunder18 / poptotal,
            sens_age = (age65up + ageunder18) / poptotal,
            pd_any = anydis / cdenom) %>%
  pivot_longer(names_to = "variable", values_to = "MEANRAW2", -rgn)

md_gee <- 
  tribble(~rgn, ~variable, ~MEANRAW2,
          "twin cities", "canopy_percent", ctu_list_raw$avgcanopy[1], 
          "twin cities", "canopy_percent2", ctu_list_raw$avgcanopy[1]
  )

metadata <- bg_growingshade_main %>%
  dplyr::group_by(type, name, variable, interpret_high_value, cc, ej, ph, cons) %>%
  dplyr::count() %>%
  dplyr::ungroup() %>%
  full_join(md1) %>%
  mutate(niceinterp = 
               case_when(interpret_high_value == "high_opportunity" ~ "Higher",
                         TRUE ~ "Lower"),
         nicer_interp = case_when(niceinterp == "Lower" ~ "Lower values = higher priority", 
                                  variable == "inverse_ndvi_uncultivated" ~ "Higher values = higher priority",
                                  variable == "inverse_ndvi_land" ~ "Higher values = higher priority",
                                  variable == "canopy_percent2" ~ "Higher values = higher priority",
                                  TRUE ~ "")) %>%
  full_join(acs_metadata %>%
              bind_rows(md_gee)) %>%
  mutate(MEANRAW = if_else(!is.na(MEANRAW2), MEANRAW2, MEANRAW)) %>%
  dplyr::select(-MEANRAW2, -rgn)

usethis::use_data(metadata, overwrite = TRUE)

```



## Highest priority for each block group

For storymap and to make database. 

```{r}
highest_p <- function(x) {
  test <- enquo(x)
  
   bg_growingshade_main %>%
  filter(name %in% (metadata %>%
                      filter(!!test == 1)))
}

highest_p(ph)

highest_p <- function(group_var) {
  selectedvars <- metadata %>%
    filter(!!enquo(group_var) == 1) %>%
    .[,2]
  bg_growingshade_main %>% 
    filter(name %in% selectedvars$name) %>%
      group_by(tract_string) %>%
      summarise(MEAN = mean(weights_scaled, na.rm = T))
}

priority_summary_1 <-highest_p(ph) %>% rename(`Public health` = MEAN) %>%
  full_join(highest_p(cons) %>% rename(Conservation = MEAN)) %>%
  full_join(highest_p(ej) %>% rename(`Environmental justice` = MEAN)) %>%
  full_join(highest_p(cc) %>% rename(`Climate change` = MEAN)) %>%
  pivot_longer(names_to = "preset", values_to = "score", -tract_string) 

priority_summary <- priority_summary_1 %>%
  group_by(tract_string) %>%
  summarise(score = max(score)) %>%
  left_join(priority_summary_1) %>%
  rename(highest_priority = preset) %>%
  rename(GEOID = tract_string)

```


highest priority all

```{r include=F, eval = F}

highest_p_all <- function(group_var) {
  selectedvars <- metadata %>%
    filter(!!enquo(group_var) == 1) %>%
    .[,2]
  bg_growingshade_main_allMN %>% 
    filter(name %in% selectedvars$name) %>%
      group_by(tract_string) %>%
      summarise(MEAN = mean(weights_scaled, na.rm = F))
}

priority_summary_1_all <-highest_p_all(ph) %>% rename(`Public health` = MEAN) %>%
  full_join(highest_p_all(cons) %>% rename(Conservation = MEAN)) %>%
  full_join(highest_p_all(ej) %>% rename(`Environmental justice` = MEAN)) %>%
  full_join(highest_p_all(cc) %>% rename(`Climate change` = MEAN)) %>%
  pivot_longer(names_to = "preset", values_to = "score", -tract_string) 

priority_summary_all <- priority_summary_1_all %>%
  pivot_wider(names_from = preset, values_from = score) %>%
  left_join(bg_growingshade_main_allMN %>%
  rename(scaled = weights_scaled,
         raw = raw_value) %>%
  # ungroup() %>%
  dplyr::select(tract_string, variable, scaled, raw) %>%
  pivot_wider(names_from = variable, values_from = c(scaled, raw))) %>%
  arrange(tract_string) %>%
  rename(block_group_id_2010 = tract_string)



bg_geo %>%
  right_join(priority_summary_all, by = c("GEOID" = "block_group_id_2010")) %>%
  filter(!is.na(`Environmental justice`)) %>%
  ggplot() +
  geom_sf(aes(fill = `Environmental justice`), lwd = 0) +
  theme_minimal()

```

# Export data


```{r bg_shapefiles_for_mapping}

mn_bgs_raw <- bg_geo %>%
  right_join(wide_ctu_crosswalk) %>%
  full_join(bg_canopy %>% rename(GEOID = bg20)) %>%
  full_join(priority_summary) %>%
  full_join(priority_summary_1%>%
              group_by(preset) %>% 
              # mutate(rank = rank(-score)) %>%
              # dplyr::select(-score) %>%
              pivot_wider(names_from = preset, values_from = score)#rank)
            %>% rename(GEOID = tract_string)) %>%
  mutate(avgcanopy = mean(canopy_percent, na.rm = T)) %>%
  dplyr::select(-STATEFP, -COUNTYFP, -TRACTCE, -BLKGRPCE, -NAMELSAD, -MTFCC, -FUNCSTAT, -INTPTLAT, -INTPTLON) %>%
  sf::st_as_sf() %>%
      sf::st_transform(4326) %>% 
  filter(!is.na(highest_priority)) %>% #don't want greater mn in here
    mutate(fancyname = case_when(substr(GEOID, 3, 5) == "053" ~ paste0("Hennepin County tract ", as.numeric(substr(GEOID, 6, 11))/100, ", block group ", as.numeric(substr(GEOID, 12, 12))),
                               substr(GEOID, 3, 5) == "003" ~ paste0("Anoka County tract ", as.numeric(substr(GEOID, 6, 11))/100, ", block group ", as.numeric(substr(GEOID, 12, 12))),
                               substr(GEOID, 3, 5) == "019" ~ paste0("Carver County tract ", as.numeric(substr(GEOID, 6, 11))/100, ", block group ", as.numeric(substr(GEOID, 12, 12))),
                               substr(GEOID, 3, 5) == "037" ~ paste0("Dakota County tract ", as.numeric(substr(GEOID, 6, 11))/100, ", block group ", as.numeric(substr(GEOID, 12, 12))),
                               substr(GEOID, 3, 5) == "123" ~ paste0("Ramsey County tract ", as.numeric(substr(GEOID, 6, 11))/100, ", block group ", as.numeric(substr(GEOID, 12, 12))),
                               substr(GEOID, 3, 5) == "139" ~ paste0("Scott County tract ", as.numeric(substr(GEOID, 6, 11))/100, ", block group ", as.numeric(substr(GEOID, 12, 12))),
                               substr(GEOID, 3, 5) == "163" ~ paste0("Washington County tract ", as.numeric(substr(GEOID, 6, 11))/100, ", block group ", as.numeric(substr(GEOID, 12, 12))),
                               TRUE ~ NA_character_))

# usethis::use_data(mn_bgs, overwrite = TRUE)


mncounties <- tigris::counties(state = "MN") %>%
  filter(COUNTYFP %in% c("003", "019", "037", "053", "123", "139", "163"))
metc_region <- mncounties %>% group_by(COUNTYFP) %>% summarise(geometry = sf::st_union(geometry)) %>%
  sf::st_simplify(dTolerance = 400) %>%
  sf::st_transform(4326)
usethis::use_data(metc_region, overwrite = TRUE)

```


# Simplify data for speed

```{r}
speed_up <- function(x, smooth){
  x %>%
  sf::st_transform(26915) %>%
  sf::st_simplify(dTolerance = smooth, preserveTopology = T) %>%
  sf::st_transform(4326)
    
}
# nhood_list <- nhood_list %>% st_make_valid() %>% st_simplify(dTolerance = 100) %>% st_as_sf()
ctu_list <- ctu_list_raw %>%
  sf::st_transform(4326)
usethis::use_data(ctu_list, overwrite = TRUE)

nhood_list <- nhood_list_raw %>% 
  speed_up(50)
usethis::use_data(nhood_list, overwrite = TRUE)

redline <- redline_raw %>% 
  speed_up(50)
usethis::use_data(redline, overwrite = TRUE)

# lakes <- river_lake_all %>%
#   filter(SYSTEM %in% c("Lake"),
#          AREA_ACRES > 10) %>% #these rivers are boundaries
#   sf::st_transform(26915) %>%
#   st_union() %>%
#   st_buffer(-10) %>%
#   # smoothr::smooth(method = "ksmooth") %>%
#   sf::st_simplify(dTolerance = 50, preserveTopology = F) #There’s also a parameter preserveTopology which, when set to TRUE, makes sure that polygons are not reduced to lines or even removed, or that inner holes in them are removed during the simplification process.

# temp <- tempfile()
# download.file("https://resources.gisdata.mn.gov/pub/gdrs/data/pub/us_mn_state_dot/trans_airports/gpkg_trans_airports.zip", destfile = temp)
# airports <- sf::read_sf(unzip(temp, "trans_airports.gpkg"))  %>%
#   st_buffer(dist = .$RUNWAY_WID) %>%
#   st_union() %>%
#   # ggplot() + geom_sf()
#   # sf::st_simplify(dTolerance = 25, preserveTopology = F) %>%
#   sf::st_transform(4326) 
  

mn_bgs <- mn_bgs_raw %>% 
  # if I want to remove lakes; I don't love them removed tbh
  # st_transform(26915) %>%
  # st_erase(lakes) %>% 
  # st_erase(airports) %>%
  sf::st_simplify(dTolerance = 25, preserveTopology = T) %>%
  sf::st_transform(4326) %>%
  filter(!is.na(GEOID))
usethis::use_data(mn_bgs, overwrite = TRUE)


# leaflet::leaflet() %>%
#   leaflet::addPolygons(data = mn_bgs) %>%
#   leaflet::addPolygons(data = mn_bgs5, color = "red")
# object.size(mn_bgs) / 1e5
# object.size(mn_bgs5) / 1e5

bg_growingshade_main <- bg_growingshade_main %>%
  dplyr::select(tract_string, name, weights_scaled, raw_value)
usethis::use_data(bg_growingshade_main, overwrite = TRUE)

# eab <- eab %>% dplyr::select(geometry)
# usethis::use_data(eab, overwrite = TRUE)

# object.size(eab2) / 1e5
# object.size(eab) / 1e5
# # ggplot() +
# #   geom_sf(data = ctu_list) +
# #   geom_sf(data = ctu_list2, col = "blue", fill = NA)

```

STOP running
```{r}
filter(bg_growingshade_data, alkdjf ="daklsjf;")

library(tidyverse); library(sf)
bg_growingshade_main %>%
  filter(variable %in% c("pbipoc", "canopy_percent")) %>%
  dplyr::select(tract_string, variable, raw_value) %>%
  pivot_wider(names_from = variable, values_from = raw_value) %>%
  filter(canopy_percent < .01)# %>% #, canopy_percent > .15)
  ggplot(aes(x = pbipoc, y = canopy_percent)) + 
  geom_point(alpha = .4) + 
  geom_smooth()
  
filter(bg_growingshade_data, tract_string == "270531044003")  
filter(ctu_crosswalk, tract_id == "270531044003")  
```


# Export for PlanIt

```{r}
ctu_list %>%
  sf::st_drop_geometry() %>%
  dplyr::select(GEO_NAME, canopy_percent, min, max) %>%
  mutate(min = min/100, 
         max = max/100) %>%
  rename("CTU Name" = GEO_NAME,
         "Average tree %" = canopy_percent,
         "Lowest block group tree %" = min,
         "Highest block group tree %" = max) %>%
  write_csv("./PlanIttriva.csv")


ctu_list %>%
  sf::st_drop_geometry() %>%
  dplyr::select(GEO_NAME, canopy_percent) %>%
  mutate(canopy_percent = case_when(canopy_percent < .10 ~ "<10%",
                                    canopy_percent <=.2 ~ "10-20%",
                                    canopy_percent <=.3~ "20-30%",
                                    canopy_percent <=.4 ~ "30-40%",
                                    canopy_percent <=.5 ~ "40-50%",
                                    TRUE ~ ">50%")) %>%
  count(canopy_percent) %>%
  mutate(total_com = sum(n),
         n = n / total_com) %>%
  mutate(canopy_percent = factor(canopy_percent, levels=c("<10%", "10-20%", "20-30%", "30-40%", "40-50%", ">50%"))) %>%
  ggplot(aes(y = fct_rev(canopy_percent), x = n,
             label = paste0(round(n*100,1), "%"))) +
  geom_bar(stat = "identity",
           width = .5)+
  labs(y = "2021\ntree\ncanopy", x = "Percent of communities") +
  theme_minimal() +
  theme(axis.title.y = element_text(angle = 0, vjust = .5)) +
  scale_x_continuous(labels = scales::percent, limits = c(0,.4)) +
  ggrepel::geom_label_repel(nudge_x = 10,segment.color = NA)


```

# Export data for storymaps

```{r storymap-shp, include = F, eval = F}
race_exp <- bg_growingshade_main %>%
  filter(variable == "pbipoc") %>%
  mutate(raw_value = raw_value * 100) %>%
  left_join(bg_geo %>% rename(tract_string = GEOID)) %>%
  dplyr::select(tract_string, raw_value, geometry) %>%
  rename(pbipoc = raw_value) %>%
  st_as_sf()

sf::st_write(race_exp, "/Users/escheh/Documents/GitHub/planting.shade/storymap-info/shapefiles/race.shp", append = FALSE)


canopy_exp <- bg_growingshade_main %>%
  filter(variable == "canopy_percent") %>%
  mutate(raw_value = raw_value * 100) %>%
  left_join(bg_geo %>% rename(tract_string = GEOID)) %>%
  dplyr::select(tract_string, raw_value, geometry) %>%
  rename(canopy_percent = raw_value) %>%
  st_as_sf()

sf::st_write(canopy_exp, "/Users/escheh/Documents/GitHub/planting.shade/storymap-info/shapefiles/canopy.shp", append = FALSE)


income_exp <- bg_growingshade_main %>%
  filter(variable == "mdhhincnow") %>%
  mutate(raw_value = raw_value * 100) %>%
  left_join(bg_geo %>% rename(tract_string = GEOID)) %>%
  dplyr::select(tract_string, raw_value, geometry) %>%
  rename(mdhhincnow = raw_value) %>%
  st_as_sf()

sf::st_write(income_exp, "/Users/escheh/Documents/GitHub/planting.shade/storymap-info/shapefiles/income.shp", append = FALSE)


copd_exp <- bg_growingshade_main %>%
  filter(variable == "COPD") %>%
  mutate(raw_value = raw_value * 100) %>%
  left_join(bg_geo %>% rename(tract_string = GEOID)) %>%
  dplyr::select(tract_string, raw_value, geometry) %>%
  rename(COPD = raw_value) %>%
  st_as_sf()

sf::st_write(copd_exp, "/Users/escheh/Documents/GitHub/planting.shade/storymap-info/shapefiles/copd.shp", append = FALSE)


highestp_exp <- bg_geo %>%
  right_join(mn_bgs %>%
               sf::st_drop_geometry()) %>%
               select(GEOID, highest_priority)
sf::st_write(highestp_exp, "/Users/escheh/Documents/GitHub/planting.shade/storymap-info/shapefiles/highestpriority.shp", append = FALSE)

```


```{r treetrust-fig, include=F, eval=F}
# https://www.bls.gov/cpi/tables/supplemental-files/historical-cpi-u-202111.pdf
cpi05 <- 193.2
cpi21 <-  266.236
tribble(~`Benefits`, ~`Total ($)`, ~`SE ($)`, ~`$/tree`, ~`SE ($/tree)`, ~`$/capita`, ~`SE ($/capita)`,
 "Energy", 6824046, (483981), 34.36, (2.44), 8.79, (.62),
 "CO2", 826875, (58644), 4.16, (.3), 1.06, (.08),
 "Air quality", 1134334, (80450), 5.71, (.41), 1.46, (.1),
 "Stormwater", 9071809, (643399), 45.67, (3.24), 11.68, (.83),
 "Aesthetic/Other", 7076370, (501877), 35.63, (2.53), 9.11, (.65),
"Total Benefits", 24933434, (1766384), 125.53, (8.89), 32.10, (2.27)) %>%
  mutate(Total21 = `$/tree` * cpi21/cpi05) %>%
  ggplot(aes(x = Total21, y = Benefits)) +
  geom_point()




```

# carbon by tree stands from USForest Service EVALIDATOR

adapted from: https://extension.umn.edu/managing-woodlands/carbon-minnesota-trees-and-woodlands#manage-for-carbon-storage-2244060

access on web at: https://apps.fs.usda.gov/Evalidator/rest/Evalidator/fullreport?reptype=State&lat=0&lon=0&radius=0&snum=Aboveground and belowground carbon in live trees (at least 1 inch d.b.h./d.r.c), in short tons, on forest land&sdenom=Area of forest land, in acres&wc=272019&pselected=None&rselected=Forest Type MnDNR&cselected=Stand age 20 yr classes (0 to 100 plus)&ptime=Current&rtime=Current&ctime=Current&wf=&wnum=&wnumdenom=&FIAorRPA=FIADEF&outputFormat=HTML&estOnly=Y&schemaName=FS_FIADB.


```{r carbon-stand-age, include = F, eval = F}
usfs <- readxl::read_xlsx("../data-raw/evalidator fsusda.xlsx", 
                          skip = 1,
                          na = "-") %>%
  dplyr::select(-Total) %>%
  pivot_longer(names_to = "age",
               values_to = "carbon", 
               -`Forest Type MnDNR`) %>%
  rename("sps" = "Forest Type MnDNR") %>%
  filter(sps %not_in% c("Total", "Other",
                        "Other softwoods", "Non stocked",
                        "Cottonwood / Willow", "Eastern redcedar", "Balsam poplar", "White spruce", "Black spruce", "Balsam fir"))%>%
    mutate(age2 = case_when(age == "0-20 years" ~ "0-20",
                          age == "21-40 years" ~ "21-40",
                          age == "41-60 years" ~ "41-60",
                          age == "61-80 years" ~ "61-80",
                          age == "81-100 years" ~ "81-100",
                          age == "100+ years" ~ "100+",
                          TRUE ~ NA_character_)) %>%
  # group_by(sps) %>%
  mutate(age2 = factor(age2, levels=c("0-20",
                                    "21-40",
                                    "41-60",
                                    "61-80",
                                    "81-100",
                                    "100+")),
         label = case_when(age2 == "100+" ~ sps,
                           TRUE ~ NA_character_),
                  sps = fct_reorder(sps, desc(carbon))
         ) 


usfs_fig <- usfs %>%
  # group_by(sps)  %>%
  ggplot(aes(x = age2, y = carbon, color = sps, group = sps, shape = sps)) +
geom_line(lwd =1) +
  geom_point(aes(fill = sps),  size = 3) +
  # cowplot::theme_cowplot() +
  councilR::council_theme() +
  scale_color_brewer(palette = "Paired") +
  scale_fill_brewer(palette = "Paired") +
  # ggrepel::geom_label_repel(aes(label = label),
  #                 nudge_x = 1,
  #                 na.rm = TRUE
  #                 )
  ggrepel::geom_label_repel(
    aes("100+", carbon, label = label), col = "black", nudge_x = .5, direction = "y", hjust = "left",  ylim = c(-Inf, Inf),  xlim = c(NA, Inf)
  ) +
  scale_x_discrete(expand = expansion(mult = c(.05, 0.6))) +
  scale_shape_manual(values = rep((21:25), 3)) +
  guides(fill = "none", col = "none", shape = "none") +
  labs(x = "Stand age (years)", y = "Average\ncarbon\nstorage\n(US tons\nper acre)",
       caption = "US Forest Service EVALIDator v1.8.0.01") +
    theme(panel.grid.minor = element_blank(),
        panel.grid.major.x = element_blank(),
        axis.title.y = element_text(angle=0,
                                    vjust = .5),
        plot.margin = margin(7,7,7,7),
        legend.position = "none"#,
        # axis.ticks.x = element_line("grey")
        )

ggsave("./usfs_fig.jpg", usfs_fig,  width = 8, height = 5, units = "in", device = "jpg")

```




```{r testdl, include=F, eval=F}
# eh<-  sf::read_sf("/Users/escheh/Downloads/Data_shpExport/BufferedTracks.shp")
# 
# eh %>%
#   ggplot() +
#   geom_sf(aes(fill = Prcnttc))
```


ampo

```{r}
a <- bg_growingshade_main %>% 
  filter(variable %in% c("mdhhincnow", "canopy_percent", "pbipoc")) %>%
  dplyr::select(-name, -weights_scaled) %>%
  pivot_wider(names_from = variable, values_from = raw_value)

car::Anova(lm(canopy_percent ~ mdhhincnow, data = a))
car::Anova(lm(canopy_percent ~ pbipoc, data = a))

mn_bgs %>% sf::st_drop_geometry() %>% group_by(highest_priority) %>% count() %>%
  mutate(n = n/ nrow(mn_bgs))
```



